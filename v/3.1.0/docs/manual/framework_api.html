<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Framework API &mdash; SyNAP 3.1.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/synaptics_theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/synaptics_theme.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Neural Network Processing Unit Operator Support" href="npu_operators.html" />
    <link rel="prev" title="Working With Models" href="working_with_models.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            SyNAP
          </a>
              <div class="version">
                3.1.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="nnapi.html">Using Online Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">Reference Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="statistics.html">Statistics And Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="working_with_models.html">Working With Models</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Framework API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#basic-usage">Basic Usage</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#network-class">Network Class</a></li>
<li class="toctree-l3"><a class="reference internal" href="#using-a-network">Using A Network</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#advanced-topics">Advanced Topics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#tensors">Tensors</a></li>
<li class="toctree-l3"><a class="reference internal" href="#buffers">Buffers</a></li>
<li class="toctree-l3"><a class="reference internal" href="#allocators">Allocators</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#advanced-examples">Advanced Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#accessing-tensor-data">Accessing Tensor Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#setting-buffers">Setting Buffers</a></li>
<li class="toctree-l3"><a class="reference internal" href="#settings-default-buffer-properties">Settings Default Buffer Properties</a></li>
<li class="toctree-l3"><a class="reference internal" href="#buffer-sharing">Buffer Sharing</a></li>
<li class="toctree-l3"><a class="reference internal" href="#recycling-buffers">Recycling Buffers</a></li>
<li class="toctree-l3"><a class="reference internal" href="#using-buffercache">Using BufferCache</a></li>
<li class="toctree-l3"><a class="reference internal" href="#copying-and-moving">Copying And Moving</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#npu-locking">NPU Locking</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id2">NPU Locking</a></li>
<li class="toctree-l3"><a class="reference internal" href="#nnapi-locking">NNAPI Locking</a></li>
<li class="toctree-l3"><a class="reference internal" href="#description">Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sample-usage">Sample Usage</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#preprocessing-and-postprocessing">Preprocessing And Postprocessing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#inputdata-class">InputData Class</a></li>
<li class="toctree-l3"><a class="reference internal" href="#preprocessor-class">Preprocessor Class</a></li>
<li class="toctree-l3"><a class="reference internal" href="#imagepostprocessor-class">ImagePostprocessor Class</a></li>
<li class="toctree-l3"><a class="reference internal" href="#classifier-class">Classifier Class</a></li>
<li class="toctree-l3"><a class="reference internal" href="#detector-class">Detector Class</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#building-sample-code">Building Sample Code</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="npu_operators.html">Neural Network Processing Unit Operator Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="java.html">Direct Access In Android Applications</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">SyNAP</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Framework API</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="framework-api">
<h1>Framework API<a class="headerlink" href="#framework-api" title="Permalink to this headline"></a></h1>
<p>The core functionality of the Synap framework is to execute a precompiled neural network.
This is done via the <code class="code docutils literal notranslate"><span class="pre">Network</span></code> class. The Network class has been designed to be simple to use
in the most common cases while still being flexible enough for most advanced use-cases.
The actual inference will take place on different HW units (NPU, GPU, CPU or a combination of them)
according to how the model has been compiled.</p>
<section id="basic-usage">
<h2>Basic Usage<a class="headerlink" href="#basic-usage" title="Permalink to this headline"></a></h2>
<section id="network-class">
<h3>Network Class<a class="headerlink" href="#network-class" title="Permalink to this headline"></a></h3>
<p>The <code class="code docutils literal notranslate"><span class="pre">Network</span></code> class is extremely simple, as shown in the picture here below.</p>
<p>There are just two things that can be done with a network:</p>
<blockquote>
<div><ul class="simple">
<li><p>load a model, by providing the compiled model in <code class="docutils literal notranslate"><span class="pre">.synap</span></code> format</p></li>
<li><p>execute an inference</p></li>
</ul>
</div></blockquote>
<p>A network also has an array of input tensors where to put the data to be processed,
and an array of output tensors which will contain the result(s) after each inference.</p>
<figure class="align-default" id="id4">
<p class="plantuml">
<a href="_images/plantuml-dec2a46d5c8bb07635f40b43e88d0afc9e0eec34.png"><img src="_images/plantuml-dec2a46d5c8bb07635f40b43e88d0afc9e0eec34.png" alt="skinparam monochrome true
skinparam handwritten false
class Network {
    bool load_model(model)
    bool predict()

    Tensor inputs[]
    Tensor outputs[]
}" style="width: 93.6px; height: 76.05px"/></a>
</p>
<figcaption>
<p><span class="caption-number">Figure 5 </span><span class="caption-text">Network class</span><a class="headerlink" href="#id4" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<dl class="cpp class">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap7NetworkE">
<span id="_CPPv3N9synaptics5synap7NetworkE"></span><span id="_CPPv2N9synaptics5synap7NetworkE"></span><span id="synaptics::synap::Network"></span><span class="target" id="classsynaptics_1_1synap_1_1Network"></span><span class="k"><span class="pre">class</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">synaptics</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">synap</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">Network</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap7NetworkE" title="Permalink to this definition"></a><br /></dt>
<dd><p>Load and execute a neural network on the NPU accelerator. </p>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric" id="breathe-section-title-public-functions">Public Functions</p>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap7Network10load_modelERKNSt6stringERKNSt6stringE">
<span id="_CPPv3N9synaptics5synap7Network10load_modelERKNSt6stringERKNSt6stringE"></span><span id="_CPPv2N9synaptics5synap7Network10load_modelERKNSt6stringERKNSt6stringE"></span><span id="synaptics::synap::Network::load_model__ssCR.ssCR"></span><span class="target" id="classsynaptics_1_1synap_1_1Network_1ab80700dd3736fd2e12347a0e682f580d"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">load_model</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">model_file</span></span>, <span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">meta_file</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="s"><span class="pre">&quot;&quot;</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap7Network10load_modelERKNSt6stringERKNSt6stringE" title="Permalink to this definition"></a><br /></dt>
<dd><p>Load model. </p>
<p>In case another model was previously loaded it is disposed before loading the one specified.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_file</strong> – path to .synap model file. Can also be the path to a legacy .nb model file. </p></li>
<li><p><strong>meta_file</strong> – for legacy .nb models must be the path to the model’s metadata file (JSON-formatted). In all other cases must be the empty string. </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>true if success </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap7Network10load_modelEPKv6size_tPKc">
<span id="_CPPv3N9synaptics5synap7Network10load_modelEPKv6size_tPKc"></span><span id="_CPPv2N9synaptics5synap7Network10load_modelEPKv6size_tPKc"></span><span id="synaptics::synap::Network::load_model__voidCP.s.cCP"></span><span class="target" id="classsynaptics_1_1synap_1_1Network_1a3a57ede4795c5d648aa96a25ddabdafb"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">load_model</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="n sig-param"><span class="pre">model_data</span></span>, <span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">model_size</span></span>, <span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="kt"><span class="pre">char</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="n sig-param"><span class="pre">meta_data</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">nullptr</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap7Network10load_modelEPKv6size_tPKc" title="Permalink to this definition"></a><br /></dt>
<dd><p>Load model. </p>
<p>In case another model was previously loaded it is disposed before loading the one specified.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_data</strong> – model data, as from e.g. fread() of model.synap The caller retains ownership of the model data and can delete them at the end of this method. </p></li>
<li><p><strong>model_size</strong> – model size in bytes </p></li>
<li><p><strong>meta_data</strong> – for legacy .nb models must be the model’s metadata (JSON-formatted). In all other cases must be nullptr. </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>true if success </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap7Network7predictEv">
<span id="_CPPv3N9synaptics5synap7Network7predictEv"></span><span id="_CPPv2N9synaptics5synap7Network7predictEv"></span><span id="synaptics::synap::Network::predict"></span><span class="target" id="classsynaptics_1_1synap_1_1Network_1a6b112c55e5867a63ca23fd2f31bcbe1c"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">predict</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap7Network7predictEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Run inference. </p>
<p>Input data to be processed are read from input tensor(s). Inference results are generated in output tensor(s).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>true if success, false if inference failed or network not correctly initialized. </p>
</dd>
</dl>
</dd></dl>

</div>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric" id="breathe-section-title-public-members">Public Members</p>
<dl class="cpp var">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap7Network6inputsE">
<span id="_CPPv3N9synaptics5synap7Network6inputsE"></span><span id="_CPPv2N9synaptics5synap7Network6inputsE"></span><span id="synaptics::synap::Network::inputs__Tensors"></span><span class="target" id="classsynaptics_1_1synap_1_1Network_1ae9e51b1bb5ef6179b2f06d52c737e84d"></span><span class="n"><span class="pre">Tensors</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">inputs</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap7Network6inputsE" title="Permalink to this definition"></a><br /></dt>
<dd><p>Collection of input tensors that can be accessed by index and iterated. </p>
</dd></dl>

<dl class="cpp var">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap7Network7outputsE">
<span id="_CPPv3N9synaptics5synap7Network7outputsE"></span><span id="_CPPv2N9synaptics5synap7Network7outputsE"></span><span id="synaptics::synap::Network::outputs__Tensors"></span><span class="target" id="classsynaptics_1_1synap_1_1Network_1aaf5e6bf3d8ebd1a0c949b78a2b3a1838"></span><span class="n"><span class="pre">Tensors</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">outputs</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap7Network7outputsE" title="Permalink to this definition"></a><br /></dt>
<dd><p>Collection of output tensors that can be accessed by index and iterated. </p>
</dd></dl>

</div>
</dd></dl>

</section>
<section id="using-a-network">
<h3>Using A Network<a class="headerlink" href="#using-a-network" title="Permalink to this headline"></a></h3>
<p>The prerequisite in order to execute a neural network is to create a <em>Network</em> object and load its
model in <code class="docutils literal notranslate"><span class="pre">.synap</span></code> format. This file is generated when the network is converted using the
Synap toolkit.
This has to be done only once, after a network has been loaded it is ready to be used for inference:</p>
<ol class="arabic simple">
<li><p>put the input data in the Network input tensor(s)</p></li>
<li><p>call network <code class="code docutils literal notranslate"><span class="pre">predict()</span></code> method</p></li>
<li><p>get the results from the Network input tensor(s)</p></li>
</ol>
<figure class="align-default" id="id5">
<p class="plantuml">
<a href="_images/plantuml-4e11ef66508b1ceedc09ec6f8d8acb2da6350cc7.png"><img src="_images/plantuml-4e11ef66508b1ceedc09ec6f8d8acb2da6350cc7.png" alt="skinparam monochrome true
skinparam handwritten false
hide footbox
autoactivate on

user -&gt; Network : load(model)
return true
loop
    user -&gt; Network : input[0].assign(data)
    return true
    user -&gt; Network : predict
    return true
    user -&gt; Network : read output[0].data()
end" style="width: 145.8px; height: 184.8px"/></a>
</p>
<figcaption>
<p><span class="caption-number">Figure 6 </span><span class="caption-text">Running inference</span><a class="headerlink" href="#id5" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>Example:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Network</span><span class="w"> </span><span class="n">net</span><span class="p">;</span><span class="w"></span>
<span class="n">net</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">&quot;model.synap&quot;</span><span class="p">);</span><span class="w"></span>
<span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">in_data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">custom_read_input_data</span><span class="p">();</span><span class="w"></span>
<span class="n">net</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">assign</span><span class="p">(</span><span class="n">in_data</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">in_data</span><span class="p">.</span><span class="n">size</span><span class="p">());</span><span class="w"></span>
<span class="n">net</span><span class="p">.</span><span class="n">predict</span><span class="p">();</span><span class="w"></span>
<span class="n">custom_process_result</span><span class="p">(</span><span class="n">net</span><span class="p">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">as_float</span><span class="p">(),</span><span class="w"> </span><span class="n">net</span><span class="p">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">item_count</span><span class="p">());</span><span class="w"></span>
</pre></div>
</div>
<p>Please note that:</p>
<blockquote>
<div><ul>
<li><p>all memory allocations and alignment for the weights and the input/ouput data are done
automatically by the Network object</p></li>
<li><p>all memory is automatically deallocated when the Network object is destroyed</p></li>
<li><p>for simplicity all error checking has been omitted, methods typically return <code class="code docutils literal notranslate"><span class="pre">false</span></code> if
something goes wrong. No explicit error code is returned since the error can often be too
complex to be explained with a simple enum code and normally there is not much the caller code
can do do to recover the situation. More detailed information on what went wrong can be found
in the logs.</p></li>
<li><p>the routines named <em>custom…</em> are just placeholders for user code in the example.</p></li>
<li><p>In the code above there is a data copy when assigning the <code class="code docutils literal notranslate"><span class="pre">in_data</span></code> vector to the tensor.
The data contained in the <code class="code docutils literal notranslate"><span class="pre">in_data</span></code> vector can’t be used directly for inference because
there is no guarantee that they are correcly aligned and padded as required by the HW.
In most cases the cost of this extra copy is negligible, when this is not the case the copy
can sometimes be avoided by writing directly inside the tensor data buffer, something like:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">custom_generate_input_data</span><span class="p">(</span><span class="n">net</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">net</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">size</span><span class="p">());</span><span class="w"></span>
<span class="n">net</span><span class="p">.</span><span class="n">predict</span><span class="p">();</span><span class="w"></span>
</pre></div>
</div>
<p>For more details see section <code class="xref std std-numref docutils literal notranslate"><span class="pre">access_tensor_data</span></code></p>
</li>
<li><p>the type of the data in a tensor depends on how the network has been generated, common data types
are <cite>float16</cite>, <cite>float32</cite> and quantized <cite>uint8</cite> and <cite>int16</cite>.
The <code class="docutils literal notranslate"><span class="pre">assign()</span></code> and <code class="docutils literal notranslate"><span class="pre">as_float()</span></code> methods take care of all the required data conversions.</p></li>
</ul>
</div></blockquote>
<p>By using just the simple methods shown in this section it is possible to perform inference with
the NPU hardware accelerator. This is almost all that one needs to know in order to use SyNAP
in most applications. The following sections explain more details of what’s going on behind the scenes:
this allows to take full advantage of the available HW for more demanding use-cases.</p>
</section>
</section>
<section id="advanced-topics">
<h2>Advanced Topics<a class="headerlink" href="#advanced-topics" title="Permalink to this headline"></a></h2>
<section id="tensors">
<h3>Tensors<a class="headerlink" href="#tensors" title="Permalink to this headline"></a></h3>
<p>We’ve seen in the previous section that all accesses to the network input and output data are done
via tensor objects, so it’s worth looking in detail at what a <code class="code docutils literal notranslate"><span class="pre">Tensor</span></code> object can do.
Basically a tensor allows to:</p>
<blockquote>
<div><ul class="simple">
<li><p>get information and attributes about the contained data</p></li>
<li><p>access data</p></li>
<li><p>access the underlying <code class="code docutils literal notranslate"><span class="pre">Buffer</span></code> used to contain data. More on this in the next section.</p></li>
</ul>
</div></blockquote>
<p>Let’s see a detailed description of the class and the available methods.</p>
<figure class="align-default" id="id6">
<p class="plantuml">
<a href="_images/plantuml-9ac1e5d2f11c9745861d6ccbb35e285b39c7ecc7.png"><img src="_images/plantuml-9ac1e5d2f11c9745861d6ccbb35e285b39c7ecc7.png" alt="skinparam monochrome true
skinparam handwritten false
class Tensor {
    string name()
    Shape shape()
    Layout layout()
    SynapType data_type()
    size_t size()
    size_t item_count()
    ..
    bool assign(data_ptr, data_size)
    void* data()
    float* as_float()
    ..
    Buffer* buffer()
    bool set_buffer(Buffer* buffer)
}" style="width: 120.25px; height: 141.7px"/></a>
</p>
<figcaption>
<p><span class="caption-number">Figure 7 </span><span class="caption-text">Tensor class</span><a class="headerlink" href="#id6" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<dl class="cpp class">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6TensorE">
<span id="_CPPv3N9synaptics5synap6TensorE"></span><span id="_CPPv2N9synaptics5synap6TensorE"></span><span id="synaptics::synap::Tensor"></span><span class="target" id="classsynaptics_1_1synap_1_1Tensor"></span><span class="k"><span class="pre">class</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">synaptics</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">synap</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap6TensorE" title="Permalink to this definition"></a><br /></dt>
<dd><p>Synap data tensor. </p>
<p>It’s not possible to create tensors outside a <a class="reference internal" href="#classsynaptics_1_1synap_1_1Network"><span class="std std-ref">Network</span></a>, users can only access tensors created by the <a class="reference internal" href="#classsynaptics_1_1synap_1_1Network"><span class="std std-ref">Network</span></a> itself. </p>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric" id="breathe-section-title-public-functions">Public Functions</p>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK9synaptics5synap6Tensor4nameEv">
<span id="_CPPv3NK9synaptics5synap6Tensor4nameEv"></span><span id="_CPPv2NK9synaptics5synap6Tensor4nameEv"></span><span id="synaptics::synap::Tensor::nameC"></span><span class="target" id="classsynaptics_1_1synap_1_1Tensor_1a24dcbf29c0d6cd766009a182a6484e3b"></span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="sig-name descname"><span class="n"><span class="pre">name</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK9synaptics5synap6Tensor4nameEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get the name of the tensor. </p>
<p>Can be useful in case of networks with multiple inputs or outputs to identify a tensor with a string instead of a positional index. </p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>tensor name </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK9synaptics5synap6Tensor5shapeEv">
<span id="_CPPv3NK9synaptics5synap6Tensor5shapeEv"></span><span id="_CPPv2NK9synaptics5synap6Tensor5shapeEv"></span><span id="synaptics::synap::Tensor::shapeC"></span><span class="target" id="classsynaptics_1_1synap_1_1Tensor_1aa9c419b07b2fbce0b082b1e955af6846"></span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">Shape</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="sig-name descname"><span class="n"><span class="pre">shape</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK9synaptics5synap6Tensor5shapeEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get the Shape of the <a class="reference internal" href="#classsynaptics_1_1synap_1_1Tensor"><span class="std std-ref">Tensor</span></a>, that is the number of elements in each dimension. </p>
<p>The order of the dimensions is specified by the tensor layout. </p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>tensor shape </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK9synaptics5synap6Tensor10dimensionsEv">
<span id="_CPPv3NK9synaptics5synap6Tensor10dimensionsEv"></span><span id="_CPPv2NK9synaptics5synap6Tensor10dimensionsEv"></span><span id="synaptics::synap::Tensor::dimensionsC"></span><span class="target" id="classsynaptics_1_1synap_1_1Tensor_1ae73ab1fa1f25866d0cdab1dd8101fbda"></span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">Dimensions</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">dimensions</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK9synaptics5synap6Tensor10dimensionsEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get the Dimensions of the <a class="reference internal" href="#classsynaptics_1_1synap_1_1Tensor"><span class="std std-ref">Tensor</span></a>, that is the number of elements in each dimension. </p>
<p>The returned values are independent of the tensor layout. </p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>tensor dimensions (all 0s if the rank of the tensor is not 4) </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK9synaptics5synap6Tensor6layoutEv">
<span id="_CPPv3NK9synaptics5synap6Tensor6layoutEv"></span><span id="_CPPv2NK9synaptics5synap6Tensor6layoutEv"></span><span id="synaptics::synap::Tensor::layoutC"></span><span class="target" id="classsynaptics_1_1synap_1_1Tensor_1a2f809fdb57d190255f105093bc5427a7"></span><span class="n"><span class="pre">Layout</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">layout</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK9synaptics5synap6Tensor6layoutEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get the layout of the <a class="reference internal" href="#classsynaptics_1_1synap_1_1Tensor"><span class="std std-ref">Tensor</span></a>, that is how data are organized in memory. </p>
<p>SyNAP supports two layouts: <code class="docutils literal notranslate"><span class="pre">NCHW</span></code> and <code class="docutils literal notranslate"><span class="pre">NHWC</span></code>. The <em>N</em> dimension (number of samples) is present for compatibility with standard conventions but must always be one. </p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>tensor layout </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK9synaptics5synap6Tensor6formatEv">
<span id="_CPPv3NK9synaptics5synap6Tensor6formatEv"></span><span id="_CPPv2NK9synaptics5synap6Tensor6formatEv"></span><span id="synaptics::synap::Tensor::formatC"></span><span class="target" id="classsynaptics_1_1synap_1_1Tensor_1a02d04e8cb490ca45ab0d15c42f051e19"></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">format</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK9synaptics5synap6Tensor6formatEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get the format of the <a class="reference internal" href="#classsynaptics_1_1synap_1_1Tensor"><span class="std std-ref">Tensor</span></a>, that is a description of what the data represents. </p>
<p>This is a free-format string whose meaning is application dependent, for example “rgb”, “bgr”. </p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>tensor format </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK9synaptics5synap6Tensor9data_typeEv">
<span id="_CPPv3NK9synaptics5synap6Tensor9data_typeEv"></span><span id="_CPPv2NK9synaptics5synap6Tensor9data_typeEv"></span><span id="synaptics::synap::Tensor::data_typeC"></span><span class="target" id="classsynaptics_1_1synap_1_1Tensor_1abef707ad21973a3062926b7b2f651562"></span><a class="reference internal" href="#_CPPv4N9synaptics5synap8DataTypeE" title="synaptics::synap::DataType"><span class="n"><span class="pre">DataType</span></span></a><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">data_type</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK9synaptics5synap6Tensor9data_typeEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get tensor data type. </p>
<p>The integral types are used to represent quantized data. The details of the quantization parameters and quantization scheme are not directly available, an user can use quantized data by converting them to 32-bits <em>float</em> using the <code class="docutils literal notranslate"><a class="reference internal" href="#classsynaptics_1_1synap_1_1Tensor_1a050845fd76be9b90925f291335131aeb"><span class="std std-ref"><span class="pre">as_float()</span></span></a></code> method below </p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the type of each item in the tensor. </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK9synaptics5synap6Tensor8securityEv">
<span id="_CPPv3NK9synaptics5synap6Tensor8securityEv"></span><span id="_CPPv2NK9synaptics5synap6Tensor8securityEv"></span><span id="synaptics::synap::Tensor::securityC"></span><span class="target" id="classsynaptics_1_1synap_1_1Tensor_1a645648a057fdad11818df51bffb712ac"></span><span class="n"><span class="pre">Security</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">security</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK9synaptics5synap6Tensor8securityEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get tensor security attribute. </p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>security attribute of the tensor (none if the model is not secure). </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK9synaptics5synap6Tensor4sizeEv">
<span id="_CPPv3NK9synaptics5synap6Tensor4sizeEv"></span><span id="_CPPv2NK9synaptics5synap6Tensor4sizeEv"></span><span id="synaptics::synap::Tensor::sizeC"></span><span class="target" id="classsynaptics_1_1synap_1_1Tensor_1a259cb5a711406a8c3e5d937eb9350cca"></span><span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">size</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK9synaptics5synap6Tensor4sizeEv" title="Permalink to this definition"></a><br /></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>size <em>in bytes</em> of the tensor data </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK9synaptics5synap6Tensor10item_countEv">
<span id="_CPPv3NK9synaptics5synap6Tensor10item_countEv"></span><span id="_CPPv2NK9synaptics5synap6Tensor10item_countEv"></span><span id="synaptics::synap::Tensor::item_countC"></span><span class="target" id="classsynaptics_1_1synap_1_1Tensor_1aa73c0c7973a3734fac48eb5b78c77d46"></span><span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">item_count</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK9synaptics5synap6Tensor10item_countEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get the number of items in the tensor. </p>
<p>A tensor <code class="docutils literal notranslate"><a class="reference internal" href="#classsynaptics_1_1synap_1_1Tensor_1a259cb5a711406a8c3e5d937eb9350cca"><span class="std std-ref"><span class="pre">size()</span></span></a></code> is alwas equal to <code class="docutils literal notranslate"><a class="reference internal" href="#classsynaptics_1_1synap_1_1Tensor_1aa73c0c7973a3734fac48eb5b78c77d46"><span class="std std-ref"><span class="pre">item_count()</span></span></a></code> multiplied by the size of the tensor data type. </p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>number of data items in the tensor </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK9synaptics5synap6Tensor9is_scalarEv">
<span id="_CPPv3NK9synaptics5synap6Tensor9is_scalarEv"></span><span id="_CPPv2NK9synaptics5synap6Tensor9is_scalarEv"></span><span id="synaptics::synap::Tensor::is_scalarC"></span><span class="target" id="classsynaptics_1_1synap_1_1Tensor_1af28caa73af1529e999f4cfc6e7b0e3a9"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">is_scalar</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK9synaptics5synap6Tensor9is_scalarEv" title="Permalink to this definition"></a><br /></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>true if this is a scalar tensor, that is it contains a single element. (the shape of a scalar tensor has one dimension, equal to 1) </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6Tensor6assignEPK7uint8_t6size_t">
<span id="_CPPv3N9synaptics5synap6Tensor6assignEPK7uint8_t6size_t"></span><span id="_CPPv2N9synaptics5synap6Tensor6assignEPK7uint8_t6size_t"></span><span id="synaptics::synap::Tensor::assign__uint8_tCP.s"></span><span class="target" id="classsynaptics_1_1synap_1_1Tensor_1a4f5e01abf26f7b08c3f9b17b2bebe865"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">assign</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">uint8_t</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="n sig-param"><span class="pre">data</span></span>, <span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">count</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap6Tensor6assignEPK7uint8_t6size_t" title="Permalink to this definition"></a><br /></dt>
<dd><p>Normalize and copy data to the tensor data buffer. </p>
<p>The data is normalized and converted to the type and quantization scheme of the tensor. The data count must be equal to the <code class="docutils literal notranslate"><a class="reference internal" href="#classsynaptics_1_1synap_1_1Tensor_1aa73c0c7973a3734fac48eb5b78c77d46"><span class="std std-ref"><span class="pre">item_count()</span></span></a></code> of the tensor. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> – pointer to data to be copied </p></li>
<li><p><strong>count</strong> – number of data items to be copied </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>true if success </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6Tensor6assignEPK7int16_t6size_t">
<span id="_CPPv3N9synaptics5synap6Tensor6assignEPK7int16_t6size_t"></span><span id="_CPPv2N9synaptics5synap6Tensor6assignEPK7int16_t6size_t"></span><span id="synaptics::synap::Tensor::assign__int16_tCP.s"></span><span class="target" id="classsynaptics_1_1synap_1_1Tensor_1a598a47173fa107663fd5d18fbe7dcb04"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">assign</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">int16_t</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="n sig-param"><span class="pre">data</span></span>, <span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">count</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap6Tensor6assignEPK7int16_t6size_t" title="Permalink to this definition"></a><br /></dt>
<dd><p>Normalize and copy data to the tensor data buffer. </p>
<p>The data is normalized and converted to the type and quantization scheme of the tensor. The data count must be equal to the <code class="docutils literal notranslate"><a class="reference internal" href="#classsynaptics_1_1synap_1_1Tensor_1aa73c0c7973a3734fac48eb5b78c77d46"><span class="std std-ref"><span class="pre">item_count()</span></span></a></code> of the tensor. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> – pointer to data to be copied </p></li>
<li><p><strong>count</strong> – number of data items to be copied </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>true if success </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6Tensor6assignEPKf6size_t">
<span id="_CPPv3N9synaptics5synap6Tensor6assignEPKf6size_t"></span><span id="_CPPv2N9synaptics5synap6Tensor6assignEPKf6size_t"></span><span id="synaptics::synap::Tensor::assign__floatCP.s"></span><span class="target" id="classsynaptics_1_1synap_1_1Tensor_1a42af454eee9038dadafdbbf14b78a56b"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">assign</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="kt"><span class="pre">float</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="n sig-param"><span class="pre">data</span></span>, <span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">count</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap6Tensor6assignEPKf6size_t" title="Permalink to this definition"></a><br /></dt>
<dd><p>Normalize and copy data to the tensor data buffer. </p>
<p>The data is normalized and converted to the type and quantization scheme of the tensor. The data count must be equal to the <code class="docutils literal notranslate"><a class="reference internal" href="#classsynaptics_1_1synap_1_1Tensor_1aa73c0c7973a3734fac48eb5b78c77d46"><span class="std std-ref"><span class="pre">item_count()</span></span></a></code> of the tensor. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> – pointer to data to be copied </p></li>
<li><p><strong>count</strong> – number of data items to be copied </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>true if success </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6Tensor6assignEPKv6size_t">
<span id="_CPPv3N9synaptics5synap6Tensor6assignEPKv6size_t"></span><span id="_CPPv2N9synaptics5synap6Tensor6assignEPKv6size_t"></span><span id="synaptics::synap::Tensor::assign__voidCP.s"></span><span class="target" id="classsynaptics_1_1synap_1_1Tensor_1a17d47e6e281d5ff2d1d1d26e1805c60b"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">assign</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="n sig-param"><span class="pre">data</span></span>, <span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">size</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap6Tensor6assignEPKv6size_t" title="Permalink to this definition"></a><br /></dt>
<dd><p>Copy raw data to the tensor data buffer. </p>
<p>The data is considered as raw data so no normalization or conversion is done whatever the actual data-type of the tensor. The data size must be equal to the <code class="docutils literal notranslate"><a class="reference internal" href="#classsynaptics_1_1synap_1_1Tensor_1a259cb5a711406a8c3e5d937eb9350cca"><span class="std std-ref"><span class="pre">size()</span></span></a></code> of the tensor. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> – pointer to data to be copied </p></li>
<li><p><strong>size</strong> – size of data to be copied </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>true if success </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6Tensor6assignERK6Tensor">
<span id="_CPPv3N9synaptics5synap6Tensor6assignERK6Tensor"></span><span id="_CPPv2N9synaptics5synap6Tensor6assignERK6Tensor"></span><span id="synaptics::synap::Tensor::assign__TensorCR"></span><span class="target" id="classsynaptics_1_1synap_1_1Tensor_1afcbaffb8ef2c465d321e3dfdcea177db"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">assign</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4N9synaptics5synap6TensorE" title="synaptics::synap::Tensor"><span class="n"><span class="pre">Tensor</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">src</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap6Tensor6assignERK6Tensor" title="Permalink to this definition"></a><br /></dt>
<dd><p>Copy the content of a tensor to the tensor data buffer. </p>
<p>No normalization or conversion is done, the data type and size of the two tensors must match </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>src</strong> – source tensor containing the data to be copied. </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>true if success, false if type or size mismatch </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6Tensor6assignE7int32_t">
<span id="_CPPv3N9synaptics5synap6Tensor6assignE7int32_t"></span><span id="_CPPv2N9synaptics5synap6Tensor6assignE7int32_t"></span><span id="synaptics::synap::Tensor::assign__int32_t"></span><span class="target" id="classsynaptics_1_1synap_1_1Tensor_1afcd57acd57f0b016985b4d49dae1aba7"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">assign</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">int32_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">value</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap6Tensor6assignE7int32_t" title="Permalink to this definition"></a><br /></dt>
<dd><p>Writes a value to the tensor data buffer. </p>
<p>Only works if the tensor is a scalar. The value is converted to the tensor data type: 8, 16 or 32 bits integer. Before writing in the data buffer the value is also rescaled if needed as specified in the tensor format attributes. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>value</strong> – value to be copied </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>true if success </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I0EN9synaptics5synap6Tensor4dataEP1Tv">
<span id="_CPPv3I0EN9synaptics5synap6Tensor4dataEv"></span><span id="_CPPv2I0EN9synaptics5synap6Tensor4dataEv"></span><span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">T</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="classsynaptics_1_1synap_1_1Tensor_1a2111245ced8081453a6de1fee008f429"></span><a class="reference internal" href="#_CPPv4I0EN9synaptics5synap6Tensor4dataEP1Tv" title="synaptics::synap::Tensor::data::T"><span class="n"><span class="pre">T</span></span></a><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="sig-name descname"><span class="n"><span class="pre">data</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I0EN9synaptics5synap6Tensor4dataEP1Tv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get a pointer to the beginning of the data inside the tensor data buffer if it can be accessed directly. </p>
<p>This is the case only if T matches the <code class="docutils literal notranslate"><a class="reference internal" href="#classsynaptics_1_1synap_1_1Tensor_1abef707ad21973a3062926b7b2f651562"><span class="std std-ref"><span class="pre">data_type()</span></span></a></code> of the tensor and no normalization/quantization is required (or normalization and quantization simplify-out each other). Sample usage:</p>
<p><code class="docutils literal notranslate"><span class="pre">uint8_t*</span> <span class="pre">data8</span> <span class="pre">=</span> <span class="pre">tensor.data&lt;uint8_t&gt;();</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>pointer to the data inside the data buffer or nullptr. </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6Tensor4dataEv">
<span id="_CPPv3N9synaptics5synap6Tensor4dataEv"></span><span id="_CPPv2N9synaptics5synap6Tensor4dataEv"></span><span id="synaptics::synap::Tensor::data"></span><span class="target" id="classsynaptics_1_1synap_1_1Tensor_1a0189be0971a32a0171c51b90a1ab1020"></span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="sig-name descname"><span class="n"><span class="pre">data</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap6Tensor4dataEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get a pointer to the beginning of the data inside the tensor data buffer, if any. </p>
<p>The method returns a <code class="docutils literal notranslate"><span class="pre">void</span></code> pointer since the actual data type is what returned by the <code class="docutils literal notranslate"><a class="reference internal" href="#classsynaptics_1_1synap_1_1Tensor_1abef707ad21973a3062926b7b2f651562"><span class="std std-ref"><span class="pre">data_type()</span></span></a></code> method. </p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>pointer to the raw data inside the data buffer, nullptr if none. </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK9synaptics5synap6Tensor8as_floatEv">
<span id="_CPPv3NK9synaptics5synap6Tensor8as_floatEv"></span><span id="_CPPv2NK9synaptics5synap6Tensor8as_floatEv"></span><span id="synaptics::synap::Tensor::as_floatC"></span><span class="target" id="classsynaptics_1_1synap_1_1Tensor_1a050845fd76be9b90925f291335131aeb"></span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="kt"><span class="pre">float</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="sig-name descname"><span class="n"><span class="pre">as_float</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK9synaptics5synap6Tensor8as_floatEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get a pointer to the tensor content converted to float. </p>
<p>The method always returns a <code class="docutils literal notranslate"><span class="pre">float</span></code> pointer. If the actual data type of the tensor is not float, the conversion is performed interally, so the user doesn’t have to care about how the data are internally represented.</p>
<p>Please note that this is a pointer to floating point data inside the tensor itself: this means that the returned pointer must <em>not</em> be freed, memory will be released automatically when the tensor is destroyed. </p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>pointer to float[<a class="reference internal" href="#classsynaptics_1_1synap_1_1Tensor_1aa73c0c7973a3734fac48eb5b78c77d46"><span class="std std-ref">item_count()</span></a>] array representing tensor content converted to float (nullptr if tensor has no data) </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6Tensor6bufferEv">
<span id="_CPPv3N9synaptics5synap6Tensor6bufferEv"></span><span id="_CPPv2N9synaptics5synap6Tensor6bufferEv"></span><span id="synaptics::synap::Tensor::buffer"></span><span class="target" id="classsynaptics_1_1synap_1_1Tensor_1a07e587c0b4c7583338e348168c4c18a8"></span><a class="reference internal" href="#_CPPv4N9synaptics5synap6BufferE" title="synaptics::synap::Buffer"><span class="n"><span class="pre">Buffer</span></span></a><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="sig-name descname"><span class="n"><span class="pre">buffer</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap6Tensor6bufferEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Get pointer to the tensor’s current data <a class="reference internal" href="#classsynaptics_1_1synap_1_1Buffer"><span class="std std-ref">Buffer</span></a> if any. </p>
<p>This will be the default buffer of the tensor unless the user has assigned a different buffer using <a class="reference internal" href="#classsynaptics_1_1synap_1_1Tensor_1a53e0d4a29388dd22e1dbdda7eef9e497"><span class="std std-ref">set_buffer()</span></a> </p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>current data buffer, or nullptr if none </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6Tensor10set_bufferEP6Buffer">
<span id="_CPPv3N9synaptics5synap6Tensor10set_bufferEP6Buffer"></span><span id="_CPPv2N9synaptics5synap6Tensor10set_bufferEP6Buffer"></span><span id="synaptics::synap::Tensor::set_buffer__BufferP"></span><span class="target" id="classsynaptics_1_1synap_1_1Tensor_1a53e0d4a29388dd22e1dbdda7eef9e497"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">set_buffer</span></span></span><span class="sig-paren">(</span><a class="reference internal" href="#_CPPv4N9synaptics5synap6BufferE" title="synaptics::synap::Buffer"><span class="n"><span class="pre">Buffer</span></span></a><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="n sig-param"><span class="pre">buffer</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap6Tensor10set_bufferEP6Buffer" title="Permalink to this definition"></a><br /></dt>
<dd><p>Set the tensor’s current data buffer. </p>
<p>The buffer size must be 0 or match the tensor size otherwise it will be rejected (empty buffers are automatically resized to the the tensor size). Normally the provided buffer should live at least as long as the tensor itself. If the buffer object is destroyed before the tensor, it will be automatically unset and the tensor will remain buffer-less. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>buffer</strong> – buffer to be used for this tensor. The buffer size must match the tensor size (or be 0). </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>true if success </p>
</dd>
</dl>
</dd></dl>

</div>
<dl class="cpp struct">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6Tensor7PrivateE">
<span id="_CPPv3N9synaptics5synap6Tensor7PrivateE"></span><span id="_CPPv2N9synaptics5synap6Tensor7PrivateE"></span><span id="synaptics::synap::Tensor::Private"></span><span class="target" id="structsynaptics_1_1synap_1_1Tensor_1_1Private"></span><span class="k"><span class="pre">struct</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Private</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap6Tensor7PrivateE" title="Permalink to this definition"></a><br /></dt>
<dd></dd></dl>

</dd></dl>

<p>Here below a list of all the data types supported in a tensor:</p>
<dl class="cpp enum-class">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8DataTypeE">
<span id="_CPPv3N9synaptics5synap8DataTypeE"></span><span id="_CPPv2N9synaptics5synap8DataTypeE"></span><span class="target" id="namespacesynaptics_1_1synap_1ad8ed01ff3ff33333d8e19db4d2818bb6"></span><span class="k"><span class="pre">enum</span></span><span class="w"> </span><span class="k"><span class="pre">class</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">synaptics</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">synap</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">DataType</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap8DataTypeE" title="Permalink to this definition"></a><br /></dt>
<dd><p><em>Values:</em></p>
<dl class="cpp enumerator">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8DataType7invalidE">
<span id="_CPPv3N9synaptics5synap8DataType7invalidE"></span><span id="_CPPv2N9synaptics5synap8DataType7invalidE"></span><span class="target" id="namespacesynaptics_1_1synap_1ad8ed01ff3ff33333d8e19db4d2818bb6afedb2d84cafe20862cb4399751a8a7e3"></span><span class="k"><span class="pre">enumerator</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">invalid</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap8DataType7invalidE" title="Permalink to this definition"></a><br /></dt>
<dd></dd></dl>

<dl class="cpp enumerator">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8DataType4byteE">
<span id="_CPPv3N9synaptics5synap8DataType4byteE"></span><span id="_CPPv2N9synaptics5synap8DataType4byteE"></span><span class="target" id="namespacesynaptics_1_1synap_1ad8ed01ff3ff33333d8e19db4d2818bb6a40ea57d3ee3c07bf1c102b466e1c3091"></span><span class="k"><span class="pre">enumerator</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">byte</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap8DataType4byteE" title="Permalink to this definition"></a><br /></dt>
<dd></dd></dl>

<dl class="cpp enumerator">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8DataType4int8E">
<span id="_CPPv3N9synaptics5synap8DataType4int8E"></span><span id="_CPPv2N9synaptics5synap8DataType4int8E"></span><span class="target" id="namespacesynaptics_1_1synap_1ad8ed01ff3ff33333d8e19db4d2818bb6a27c006cc56b1ba88f960cf8b5144fcac"></span><span class="k"><span class="pre">enumerator</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">int8</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap8DataType4int8E" title="Permalink to this definition"></a><br /></dt>
<dd></dd></dl>

<dl class="cpp enumerator">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8DataType5uint8E">
<span id="_CPPv3N9synaptics5synap8DataType5uint8E"></span><span id="_CPPv2N9synaptics5synap8DataType5uint8E"></span><span class="target" id="namespacesynaptics_1_1synap_1ad8ed01ff3ff33333d8e19db4d2818bb6a5f423e669d0a8f4ab7c4c3e6da27161a"></span><span class="k"><span class="pre">enumerator</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">uint8</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap8DataType5uint8E" title="Permalink to this definition"></a><br /></dt>
<dd></dd></dl>

<dl class="cpp enumerator">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8DataType5int16E">
<span id="_CPPv3N9synaptics5synap8DataType5int16E"></span><span id="_CPPv2N9synaptics5synap8DataType5int16E"></span><span class="target" id="namespacesynaptics_1_1synap_1ad8ed01ff3ff33333d8e19db4d2818bb6ace80d5ec65b1d2a2f1049eadc100db23"></span><span class="k"><span class="pre">enumerator</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">int16</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap8DataType5int16E" title="Permalink to this definition"></a><br /></dt>
<dd></dd></dl>

<dl class="cpp enumerator">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8DataType6uint16E">
<span id="_CPPv3N9synaptics5synap8DataType6uint16E"></span><span id="_CPPv2N9synaptics5synap8DataType6uint16E"></span><span class="target" id="namespacesynaptics_1_1synap_1ad8ed01ff3ff33333d8e19db4d2818bb6aa00ef2ef85ff67b7b39339886f19044f"></span><span class="k"><span class="pre">enumerator</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">uint16</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap8DataType6uint16E" title="Permalink to this definition"></a><br /></dt>
<dd></dd></dl>

<dl class="cpp enumerator">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8DataType5int32E">
<span id="_CPPv3N9synaptics5synap8DataType5int32E"></span><span id="_CPPv2N9synaptics5synap8DataType5int32E"></span><span class="target" id="namespacesynaptics_1_1synap_1ad8ed01ff3ff33333d8e19db4d2818bb6a0241adbbd83925f051b694d40f02747f"></span><span class="k"><span class="pre">enumerator</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">int32</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap8DataType5int32E" title="Permalink to this definition"></a><br /></dt>
<dd></dd></dl>

<dl class="cpp enumerator">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8DataType6uint32E">
<span id="_CPPv3N9synaptics5synap8DataType6uint32E"></span><span id="_CPPv2N9synaptics5synap8DataType6uint32E"></span><span class="target" id="namespacesynaptics_1_1synap_1ad8ed01ff3ff33333d8e19db4d2818bb6a3de84ad0700f2a1571f633d399e1900e"></span><span class="k"><span class="pre">enumerator</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">uint32</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap8DataType6uint32E" title="Permalink to this definition"></a><br /></dt>
<dd></dd></dl>

<dl class="cpp enumerator">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8DataType7float16E">
<span id="_CPPv3N9synaptics5synap8DataType7float16E"></span><span id="_CPPv2N9synaptics5synap8DataType7float16E"></span><span class="target" id="namespacesynaptics_1_1synap_1ad8ed01ff3ff33333d8e19db4d2818bb6a098e7844282e240fdee28a9dac11c1c6"></span><span class="k"><span class="pre">enumerator</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">float16</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap8DataType7float16E" title="Permalink to this definition"></a><br /></dt>
<dd></dd></dl>

<dl class="cpp enumerator">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8DataType7float32E">
<span id="_CPPv3N9synaptics5synap8DataType7float32E"></span><span id="_CPPv2N9synaptics5synap8DataType7float32E"></span><span class="target" id="namespacesynaptics_1_1synap_1ad8ed01ff3ff33333d8e19db4d2818bb6ad33ec2b0bbea6d471a4706cea030e1e3"></span><span class="k"><span class="pre">enumerator</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">float32</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap8DataType7float32E" title="Permalink to this definition"></a><br /></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="buffers">
<h3>Buffers<a class="headerlink" href="#buffers" title="Permalink to this headline"></a></h3>
<p>The memory used to store a tensor data has to satisfy the following requirements:</p>
<blockquote>
<div><ul class="simple">
<li><p>must be correctly aligned</p></li>
<li><p>must be correctly padded</p></li>
<li><p>in some cases must be contiguous</p></li>
<li><p>must be accessible by the NPU HW accelerator and by the CPU or other HW components</p></li>
</ul>
</div></blockquote>
<p>Memory allocated with <code class="code docutils literal notranslate"><span class="pre">malloc()</span></code> or <code class="code docutils literal notranslate"><span class="pre">new</span></code> or <code class="code docutils literal notranslate"><span class="pre">std::vector</span></code> doesn’t satisfy these
requirements so can’t be used directly as input or output of a Network.
For this reason <code class="code docutils literal notranslate"><span class="pre">Tensor</span></code> objects use a special <code class="code docutils literal notranslate"><span class="pre">Buffer</span></code> class to handle memory. Each
tensor internally contains a default Buffer object to handle the memory used for the data.</p>
<p>The API provided by the <code class="code docutils literal notranslate"><span class="pre">Buffer</span></code> is similar when possible to the one provided by
<code class="code docutils literal notranslate"><span class="pre">std::vector</span></code>. The main notable exeception is that a buffer content can’t be indexed
since a buffer is just a container for raw memory, without a <em>data type</em>.
The data type is known by the tensor which is using the buffer.
<code class="code docutils literal notranslate"><span class="pre">Buffer</span></code> is also taking care of disposing the allocated memory when it is destroyed (<em>RAII</em>)
to avoid all possible memory leakages. The actual memory allocation is done via an additional
<code class="code docutils literal notranslate"><span class="pre">Allocator</span></code> object. This allows to allocate memory with different attributes in different
memory area. When a buffer object is created it will use the default allocator unless a different
allocator is specified. The allocator can be specified directly in the constructor or later using the
<code class="code docutils literal notranslate"><span class="pre">set_allocator()</span></code> method.</p>
<figure class="align-default" id="id7">
<p class="plantuml">
<a href="_images/plantuml-fb57cbf3f8db132fe831129345685c664ccbbb1d.png"><img src="_images/plantuml-fb57cbf3f8db132fe831129345685c664ccbbb1d.png" alt="skinparam monochrome true
skinparam handwritten false
class Buffer {
    Buffer(size, allocator)
    ..
    bool resize(size)
    size_t size()
    ..
    bool assign(data_ptr, data_size)
    void* data()
    ..
    bool set_allocator(allocator)
    bool allow_cpu_access(allow)
}" style="width: 120.25px; height: 112.45px"/></a>
</p>
<figcaption>
<p><span class="caption-number">Figure 8 </span><span class="caption-text">Buffer class</span><a class="headerlink" href="#id7" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>In order for the buffer data to be shared by the CPU and NPU hardware some extra operations have
to be done to ensure that the CPU caches and system memory are correcly aligned. All this
is done automatically when the buffer content is used in the Network for inference.
There are cases when the CPU is not going to read/write the buffer data directly,
for example when the data is generated by another HW component (eg. video decoder).
In these cases it’s possible to have some performance improvements by disabling CPU access to the
buffer using the method provided.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>it is also possible to create a buffer that refers to an existing memory area instead of using
an allocator. In this case the memory area must have been registered with the TrustZone kernel
and must be correctly aligned and padded. Furthermore the Buffer object will <em>not</em> free the
memory area when it is destroyed, since the memory is supposed to be owned
by the SW module which allocated it.</p>
</div>
<dl class="cpp class">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6BufferE">
<span id="_CPPv3N9synaptics5synap6BufferE"></span><span id="_CPPv2N9synaptics5synap6BufferE"></span><span id="synaptics::synap::Buffer"></span><span class="target" id="classsynaptics_1_1synap_1_1Buffer"></span><span class="k"><span class="pre">class</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">synaptics</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">synap</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">Buffer</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap6BufferE" title="Permalink to this definition"></a><br /></dt>
<dd><p>Synap data buffer. </p>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric" id="breathe-section-title-public-functions">Public Functions</p>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6Buffer6BufferEP9Allocator">
<span id="_CPPv3N9synaptics5synap6Buffer6BufferEP9Allocator"></span><span id="_CPPv2N9synaptics5synap6Buffer6BufferEP9Allocator"></span><span id="synaptics::synap::Buffer::Buffer__AllocatorP"></span><span class="target" id="classsynaptics_1_1synap_1_1Buffer_1a59ae3c9942a27d589efee9d93e4246b2"></span><span class="sig-name descname"><span class="n"><span class="pre">Buffer</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">Allocator</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="n sig-param"><span class="pre">allocator</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">nullptr</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap6Buffer6BufferEP9Allocator" title="Permalink to this definition"></a><br /></dt>
<dd><p>Create an empty data buffer. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>allocator</strong> – allocator to be used (default is malloc-based) </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6Buffer6BufferE6size_tP9Allocator">
<span id="_CPPv3N9synaptics5synap6Buffer6BufferE6size_tP9Allocator"></span><span id="_CPPv2N9synaptics5synap6Buffer6BufferE6size_tP9Allocator"></span><span id="synaptics::synap::Buffer::Buffer__s.AllocatorP"></span><span class="target" id="classsynaptics_1_1synap_1_1Buffer_1a8ceb6ed892695e735760d93b787b5106"></span><span class="sig-name descname"><span class="n"><span class="pre">Buffer</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">size</span></span>, <span class="n"><span class="pre">Allocator</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="n sig-param"><span class="pre">allocator</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">nullptr</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap6Buffer6BufferE6size_tP9Allocator" title="Permalink to this definition"></a><br /></dt>
<dd><p>Create and allocate a data buffer. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> – buffer size </p></li>
<li><p><strong>allocator</strong> – allocator to be used (default is malloc-based) </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6Buffer6BufferE8uint32_t6size_t6size_t">
<span id="_CPPv3N9synaptics5synap6Buffer6BufferE8uint32_t6size_t6size_t"></span><span id="_CPPv2N9synaptics5synap6Buffer6BufferE8uint32_t6size_t6size_t"></span><span id="synaptics::synap::Buffer::Buffer__uint32_t.s.s"></span><span class="target" id="classsynaptics_1_1synap_1_1Buffer_1aa914ea9212066d65431c7e054af1ea82"></span><span class="sig-name descname"><span class="n"><span class="pre">Buffer</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">uint32_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">mem_id</span></span>, <span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">offset</span></span>, <span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">size</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap6Buffer6BufferE8uint32_t6size_t6size_t" title="Permalink to this definition"></a><br /></dt>
<dd><p>Create a data buffer to refer to an existing memory area. </p>
<p>The user must make sure that the provided memory is correctly aligned and padded. The specified memory area will <em>not</em> be deallocated when the buffer is destroyed. It is the responsiblity of the caller to release mem_id <em>after</em> the <a class="reference internal" href="#classsynaptics_1_1synap_1_1Buffer"><span class="std std-ref">Buffer</span></a> has been destroyed. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mem_id</strong> – id of an existing memory area registered with the TZ kernel. </p></li>
<li><p><strong>offset</strong> – offset of the actual data inside the memory area </p></li>
<li><p><strong>size</strong> – size of the actual data </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6Buffer6BufferE8uint32_t6size_t6size_tb">
<span id="_CPPv3N9synaptics5synap6Buffer6BufferE8uint32_t6size_t6size_tb"></span><span id="_CPPv2N9synaptics5synap6Buffer6BufferE8uint32_t6size_t6size_tb"></span><span id="synaptics::synap::Buffer::Buffer__uint32_t.s.s.b"></span><span class="target" id="classsynaptics_1_1synap_1_1Buffer_1a7b0f1f07cd30816eeeab191f4fd1894c"></span><span class="sig-name descname"><span class="n"><span class="pre">Buffer</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">uint32_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">handle</span></span>, <span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">offset</span></span>, <span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">size</span></span>, <span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">is_mem_id</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap6Buffer6BufferE8uint32_t6size_t6size_tb" title="Permalink to this definition"></a><br /></dt>
<dd><p>Create a data buffer to refer to an existing memory area. </p>
<p>The user must make sure that the provided memory is correctly aligned and padded. The specified memory area will <em>not</em> be deallocated when the buffer is destroyed. It is the responsiblity of the caller to release mem_id <em>after</em> the <a class="reference internal" href="#classsynaptics_1_1synap_1_1Buffer"><span class="std std-ref">Buffer</span></a> has been destroyed. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>handle</strong> – fd of an existing dmabuf or mem_id registered with the TZ kernel. </p></li>
<li><p><strong>offset</strong> – offset of the actual data inside the memory area </p></li>
<li><p><strong>size</strong> – size of the actual data </p></li>
<li><p><strong>is_mem_id</strong> – true if the first argument is a mem_id, false if it is a fd </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6Buffer6BufferERK6Buffer6size_t6size_t">
<span id="_CPPv3N9synaptics5synap6Buffer6BufferERK6Buffer6size_t6size_t"></span><span id="_CPPv2N9synaptics5synap6Buffer6BufferERK6Buffer6size_t6size_t"></span><span id="synaptics::synap::Buffer::Buffer__BufferCR.s.s"></span><span class="target" id="classsynaptics_1_1synap_1_1Buffer_1a2f52da9815eba1e24e1eb541d4f1ce28"></span><span class="sig-name descname"><span class="n"><span class="pre">Buffer</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4N9synaptics5synap6Buffer6BufferERK6Buffer6size_t6size_t" title="synaptics::synap::Buffer::Buffer"><span class="n"><span class="pre">Buffer</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">rhs</span></span>, <span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">offset</span></span>, <span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">size</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap6Buffer6BufferERK6Buffer6size_t6size_t" title="Permalink to this definition"></a><br /></dt>
<dd><p>Create a data buffer that refers to a part of the memory area of an existing buffer. </p>
<p>The memory of the provided buffer must have already been allocated. To avoid referring to released memory, the existing buffer memory must <em>not</em> be deallocated before this buffer is destroyed. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>rhs</strong> – an existing <a class="reference internal" href="#classsynaptics_1_1synap_1_1Buffer"><span class="std std-ref">Buffer</span></a> </p></li>
<li><p><strong>offset</strong> – offset of the desired data inside the <a class="reference internal" href="#classsynaptics_1_1synap_1_1Buffer"><span class="std std-ref">Buffer</span></a> memory area </p></li>
<li><p><strong>size</strong> – size of the desired data </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6Buffer6BufferERR6Buffer">
<span id="_CPPv3N9synaptics5synap6Buffer6BufferERR6Buffer"></span><span id="_CPPv2N9synaptics5synap6Buffer6BufferERR6Buffer"></span><span id="synaptics::synap::Buffer::Buffer__BufferRR"></span><span class="target" id="classsynaptics_1_1synap_1_1Buffer_1a15d2ab4c28436becc8a0934c9e236db9"></span><span class="sig-name descname"><span class="n"><span class="pre">Buffer</span></span></span><span class="sig-paren">(</span><a class="reference internal" href="#_CPPv4N9synaptics5synap6Buffer6BufferERR6Buffer" title="synaptics::synap::Buffer::Buffer"><span class="n"><span class="pre">Buffer</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">rhs</span></span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">noexcept</span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap6Buffer6BufferERR6Buffer" title="Permalink to this definition"></a><br /></dt>
<dd><p>Move constructor (only possible from buffers not yet in use by a <a class="reference internal" href="#classsynaptics_1_1synap_1_1Network"><span class="std std-ref">Network</span></a>) </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6BufferaSERR6Buffer">
<span id="_CPPv3N9synaptics5synap6BufferaSERR6Buffer"></span><span id="_CPPv2N9synaptics5synap6BufferaSERR6Buffer"></span><span id="synaptics::synap::Buffer::assign-operator__BufferRR"></span><span class="target" id="classsynaptics_1_1synap_1_1Buffer_1ae8f5f7d68d2b89ca817d80ad97eb520a"></span><a class="reference internal" href="#_CPPv4N9synaptics5synap6BufferE" title="synaptics::synap::Buffer"><span class="n"><span class="pre">Buffer</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="sig-name descname"><span class="k"><span class="pre">operator</span></span><span class="o"><span class="pre">=</span></span></span><span class="sig-paren">(</span><a class="reference internal" href="#_CPPv4N9synaptics5synap6BufferE" title="synaptics::synap::Buffer"><span class="n"><span class="pre">Buffer</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">rhs</span></span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">noexcept</span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap6BufferaSERR6Buffer" title="Permalink to this definition"></a><br /></dt>
<dd><p>Move assignment (only possible for buffers not yet in use by a <a class="reference internal" href="#classsynaptics_1_1synap_1_1Network"><span class="std std-ref">Network</span></a>) </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6Buffer6resizeE6size_t">
<span id="_CPPv3N9synaptics5synap6Buffer6resizeE6size_t"></span><span id="_CPPv2N9synaptics5synap6Buffer6resizeE6size_t"></span><span id="synaptics::synap::Buffer::resize__s"></span><span class="target" id="classsynaptics_1_1synap_1_1Buffer_1ae4f8f853ac7c7aaa49e0471d25f5e02c"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">resize</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">size</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap6Buffer6resizeE6size_t" title="Permalink to this definition"></a><br /></dt>
<dd><p>Resize buffer. </p>
<p>Only possible if an allocator was provided. Any previous content is lost.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>size</strong> – new buffer size </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>true if success </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6Buffer6assignEPKv6size_t">
<span id="_CPPv3N9synaptics5synap6Buffer6assignEPKv6size_t"></span><span id="_CPPv2N9synaptics5synap6Buffer6assignEPKv6size_t"></span><span id="synaptics::synap::Buffer::assign__voidCP.s"></span><span class="target" id="classsynaptics_1_1synap_1_1Buffer_1a17d47e6e281d5ff2d1d1d26e1805c60b"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">assign</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="n sig-param"><span class="pre">data</span></span>, <span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">size</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap6Buffer6assignEPKv6size_t" title="Permalink to this definition"></a><br /></dt>
<dd><p>Copy data in buffer. </p>
<p>Always successful if the input data size is the same as current buffer size, otherwise the buffer is resized if possible.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> – pointer to data to be copied </p></li>
<li><p><strong>size</strong> – size of data to be copied </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>true if all right </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK9synaptics5synap6Buffer4sizeEv">
<span id="_CPPv3NK9synaptics5synap6Buffer4sizeEv"></span><span id="_CPPv2NK9synaptics5synap6Buffer4sizeEv"></span><span id="synaptics::synap::Buffer::sizeC"></span><span class="target" id="classsynaptics_1_1synap_1_1Buffer_1a259cb5a711406a8c3e5d937eb9350cca"></span><span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">size</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK9synaptics5synap6Buffer4sizeEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Actual data size. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK9synaptics5synap6Buffer4dataEv">
<span id="_CPPv3NK9synaptics5synap6Buffer4dataEv"></span><span id="_CPPv2NK9synaptics5synap6Buffer4dataEv"></span><span id="synaptics::synap::Buffer::dataC"></span><span class="target" id="classsynaptics_1_1synap_1_1Buffer_1a332a750ed35277f0bc297fbfecce598f"></span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="sig-name descname"><span class="n"><span class="pre">data</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK9synaptics5synap6Buffer4dataEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Actual data. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6Buffer16allow_cpu_accessEb">
<span id="_CPPv3N9synaptics5synap6Buffer16allow_cpu_accessEb"></span><span id="_CPPv2N9synaptics5synap6Buffer16allow_cpu_accessEb"></span><span id="synaptics::synap::Buffer::allow_cpu_access__b"></span><span class="target" id="classsynaptics_1_1synap_1_1Buffer_1a16b679c85921bb5aa3cf60ef0c3ab6a9"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">allow_cpu_access</span></span></span><span class="sig-paren">(</span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">allow</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap6Buffer16allow_cpu_accessEb" title="Permalink to this definition"></a><br /></dt>
<dd><p>Enable/disable the possibility for the CPU to read/write the buffer data. </p>
<p>By default CPU access to data is enabled. CPU access can be disabled in case the CPU doesn’t need to read or write the buffer data and can provide some performance improvements when the data is only generated/used by another HW components.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>reading or writing buffer data while CPU access is disabled might cause loss or corruption of the data in the buffer.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>allow</strong> – false to indicate the CPU will not access buffer data </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>current setting </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap6Buffer13set_allocatorEP9Allocator">
<span id="_CPPv3N9synaptics5synap6Buffer13set_allocatorEP9Allocator"></span><span id="_CPPv2N9synaptics5synap6Buffer13set_allocatorEP9Allocator"></span><span id="synaptics::synap::Buffer::set_allocator__AllocatorP"></span><span class="target" id="classsynaptics_1_1synap_1_1Buffer_1abb8823642b0c9398bb25e210ad5ee628"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">set_allocator</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">Allocator</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="n sig-param"><span class="pre">allocator</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap6Buffer13set_allocatorEP9Allocator" title="Permalink to this definition"></a><br /></dt>
<dd><p>Change the allocator. </p>
<p>Can only be done if the buffer is empty. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>allocator</strong> – allocator </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>true if success </p>
</dd>
</dl>
</dd></dl>

</div>
</dd></dl>

</section>
<section id="allocators">
<h3>Allocators<a class="headerlink" href="#allocators" title="Permalink to this headline"></a></h3>
<p>Two allocators are provided for use with buffer objects:</p>
<blockquote>
<div><ul class="simple">
<li><p>the <em>standard</em> allocator: this is the default allocator used by buffers created without
explicitly specifying an allocator. The memory is paged (non-contiguous).</p></li>
<li><p>the <em>cma</em> allocator: allocates contiguous memory. Contiguous memory is required for some HW
components and can provide some small performance improvement if the input/output buffers are very large
since less overhead is required to handle memory pages.
Should be used with great care since the contiguous memory available in the system is quite limited.</p></li>
</ul>
</div></blockquote>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv413std_allocatorv">
<span id="_CPPv313std_allocatorv"></span><span id="_CPPv213std_allocatorv"></span><span id="std_allocator"></span><span class="n"><span class="pre">Allocator</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="sig-name descname"><span class="n"><span class="pre">std_allocator</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv413std_allocatorv" title="Permalink to this definition"></a><br /></dt>
<dd><p>return a pointer to the system standard allocator.</p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv413cma_allocatorv">
<span id="_CPPv313cma_allocatorv"></span><span id="_CPPv213cma_allocatorv"></span><span id="cma_allocator"></span><span class="n"><span class="pre">Allocator</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="sig-name descname"><span class="n"><span class="pre">cma_allocator</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv413cma_allocatorv" title="Permalink to this definition"></a><br /></dt>
<dd><p>return a pointer to the system contiguous allocator.</p>
</dd></dl>

<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The calls above return pointers to global objects,
so they <em>must NOT be deleted</em> after use</p>
</div>
</section>
</section>
<section id="advanced-examples">
<h2>Advanced Examples<a class="headerlink" href="#advanced-examples" title="Permalink to this headline"></a></h2>
<section id="accessing-tensor-data">
<span id="access-tensor-data"></span><h3>Accessing Tensor Data<a class="headerlink" href="#accessing-tensor-data" title="Permalink to this headline"></a></h3>
<p>Data in a Tensor is normally written using the <code class="docutils literal notranslate"><span class="pre">Tensor::assign(const</span> <span class="pre">T*</span> <span class="pre">data,</span> <span class="pre">size_t</span> <span class="pre">count)</span></code> method.
This method will take care of any required data normalization and data type conversion from
the type <code class="docutils literal notranslate"><span class="pre">T</span></code> to the internal representation used by the network.</p>
<p>Similarly the output data are normally read using the <code class="docutils literal notranslate"><span class="pre">Tensor::as_float()</span></code> method that
provides a pointer to the tensor data converted to floating point values from whatever internal
represention is used.</p>
<p>These conversions, even if quite optimized, present however a runtime cost that is proportional to
the size of the data. For input data this cost could be avoided by generating them directly in
the Tensor data buffer, but this is only possible when the tensor data type corresponds to
that of the data available in input and no additional normalization/quantization is required.
Tensor provides a type-safe <code class="docutils literal notranslate"><span class="pre">data&lt;T&gt;()</span></code> access method that will return a pointer to the data in the
tensor only if the above conditions are satisfied, for example:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">uint8_t</span><span class="o">*</span><span class="w"> </span><span class="n">data_ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">net</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">data</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;</span><span class="p">();</span><span class="w"></span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">data_ptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">   </span><span class="n">custom_generate_data</span><span class="p">(</span><span class="n">data_ptr</span><span class="p">,</span><span class="w"> </span><span class="n">net</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">item_count</span><span class="p">());</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>If the data in the tensor is not <code class="docutils literal notranslate"><span class="pre">uint8_t</span></code> or normalization/[de]quantization is required, the returned
value will be <code class="docutils literal notranslate"><span class="pre">nullptr</span></code>. In this case the direct write or read is not possible and <code class="docutils literal notranslate"><span class="pre">assign()</span></code>
or <code class="docutils literal notranslate"><span class="pre">as_float()</span></code> is required.</p>
<p>It’s always possible to access the data directly by using the raw <code class="docutils literal notranslate"><span class="pre">data()</span></code> access method which
bypasses all checks:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">in_data_ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">net</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">data</span><span class="p">();</span><span class="w"></span>
<span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">out_data_ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">net</span><span class="p">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">data</span><span class="p">();</span><span class="w"></span>
</pre></div>
</div>
<p>In the same way it’s also possible to assign raw data (without any conversion)
by using <code class="docutils literal notranslate"><span class="pre">void*</span></code> data pointer:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">const</span><span class="w"> </span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">in_raw_data_ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">....;</span><span class="w"></span>
<span class="n">net</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">assign</span><span class="p">(</span><span class="n">in_raw_data_ptr</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
<p>In these cases it’s responsibility of the user to know how the data are represented and how to
handle them.</p>
</section>
<section id="setting-buffers">
<h3>Setting Buffers<a class="headerlink" href="#setting-buffers" title="Permalink to this headline"></a></h3>
<p>If the properties of the default tensor buffer are not suitable, the user can explicity create
a new buffer and use it instead of the default one. For example suppose we want to use a buffer
with contiguous memory:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Network</span><span class="w"> </span><span class="n">net</span><span class="p">;</span><span class="w"></span>
<span class="n">net</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">&quot;model.synap&quot;</span><span class="p">);</span><span class="w"></span>

<span class="c1">// Replace the default buffer with one using contiguous memory</span>
<span class="n">Buffer</span><span class="w"> </span><span class="nf">cma_buffer</span><span class="p">(</span><span class="n">net</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">size</span><span class="p">(),</span><span class="w"> </span><span class="n">cma_allocator</span><span class="p">());</span><span class="w"></span>
<span class="n">net</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_buffer</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cma_buffer</span><span class="p">);</span><span class="w"></span>

<span class="c1">// Do inference as usual</span>
<span class="n">custom_generate_input_data</span><span class="p">(</span><span class="n">net</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">net</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">size</span><span class="p">());</span><span class="w"></span>
<span class="n">net</span><span class="p">.</span><span class="n">predict</span><span class="p">();</span><span class="w"></span>
</pre></div>
</div>
</section>
<section id="settings-default-buffer-properties">
<h3>Settings Default Buffer Properties<a class="headerlink" href="#settings-default-buffer-properties" title="Permalink to this headline"></a></h3>
<p>A simpler alternative to replacing the buffer used in a tensor as seen in the previous section
is to directly change the properties of the default tensor buffer.
This can only be done at the beginning, before the tensor data is accessed:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Network</span><span class="w"> </span><span class="n">net</span><span class="p">;</span><span class="w"></span>
<span class="n">net</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">&quot;model.synap&quot;</span><span class="p">);</span><span class="w"></span>

<span class="c1">// Use contiguous allocator for default buffer in input[0]</span>
<span class="n">net</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">buffer</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">set_allocator</span><span class="p">(</span><span class="n">cma_allocator</span><span class="p">());</span><span class="w"></span>

<span class="c1">// Do inference as usual</span>
<span class="n">custom_generate_input_data</span><span class="p">(</span><span class="n">net</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">net</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">size</span><span class="p">());</span><span class="w"></span>
<span class="n">net</span><span class="p">.</span><span class="n">predict</span><span class="p">();</span><span class="w"></span>
</pre></div>
</div>
</section>
<section id="buffer-sharing">
<span id="id1"></span><h3>Buffer Sharing<a class="headerlink" href="#buffer-sharing" title="Permalink to this headline"></a></h3>
<p>The same buffer can be shared among multiple networks if they need to process the same
input data. This avoids the need of redundant data copies:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Network</span><span class="w"> </span><span class="n">net1</span><span class="p">;</span><span class="w"></span>
<span class="n">net1</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">&quot;nbg1.synap&quot;</span><span class="p">);</span><span class="w"></span>
<span class="n">Network</span><span class="w"> </span><span class="n">net2</span><span class="p">;</span><span class="w"></span>
<span class="n">net2</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">&quot;nbg2.synap&quot;</span><span class="p">);</span><span class="w"></span>

<span class="c1">// Use a common input buffer for the two networks (assume same input size)</span>
<span class="n">Buffer</span><span class="w"> </span><span class="n">in_buffer</span><span class="p">;</span><span class="w"></span>
<span class="n">net1</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_buffer</span><span class="p">(</span><span class="o">&amp;</span><span class="n">in_buffer</span><span class="p">);</span><span class="w"></span>
<span class="n">net2</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_buffer</span><span class="p">(</span><span class="o">&amp;</span><span class="n">in_buffer</span><span class="p">);</span><span class="w"></span>

<span class="c1">// Do inference as usual</span>
<span class="n">custom_generate_input_data</span><span class="p">(</span><span class="n">in_buffer</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">in_buffer</span><span class="p">.</span><span class="n">size</span><span class="p">());</span><span class="w"></span>
<span class="n">net1</span><span class="p">.</span><span class="n">predict</span><span class="p">();</span><span class="w"></span>
<span class="n">net2</span><span class="p">.</span><span class="n">predict</span><span class="p">();</span><span class="w"></span>
</pre></div>
</div>
<p>Another interesting case of buffer sharing is when the output of a network must be processed
directly by another network. For example the first network can do some preprocessing and the second
one the actual inference.
In this case setting the output buffer of the first network as the input buffer of the second
network allows to completely avoid data copying (the two tensors must have the same size of course).
Furthermore, since the CPU has no need to access this intermediate data, it is convenient to
disable its access to this buffer, this will avoid the un-necessary overhead of cache flushing
and provide an additional improvement in performance.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Network</span><span class="w"> </span><span class="n">net1</span><span class="p">;</span><span class="w"></span>
<span class="n">net1</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">&quot;nbg1.synap&quot;</span><span class="p">);</span><span class="w"></span>
<span class="n">Network</span><span class="w"> </span><span class="n">net2</span><span class="p">;</span><span class="w"></span>
<span class="n">net2</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">&quot;nbg2.synap&quot;</span><span class="p">);</span><span class="w"></span>

<span class="c1">// Use net1 output as net2 input. Disable CPU access for better performance.</span>
<span class="n">net1</span><span class="p">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">buffer</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">allow_cpu_access</span><span class="p">(</span><span class="nb">false</span><span class="p">);</span><span class="w"></span>
<span class="n">net2</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_buffer</span><span class="p">(</span><span class="n">net1</span><span class="p">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">buffer</span><span class="p">()));</span><span class="w"></span>

<span class="c1">// Do inference as usual</span>
<span class="n">custom_generate_input_data</span><span class="p">(</span><span class="n">net1</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">net1</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">size</span><span class="p">());</span><span class="w"></span>
<span class="n">net1</span><span class="p">.</span><span class="n">predict</span><span class="p">();</span><span class="w"></span>
<span class="n">net2</span><span class="p">.</span><span class="n">predict</span><span class="p">();</span><span class="w"></span>
</pre></div>
</div>
<p>One last case is when the output of the first network is smaller than the input of the second network,
and we still want to avoid copy. Imagine for example that the output of net1 is an image 640x360 that
we want to generate inside the input of net2 which expects an image 640x480.
In this case the buffer sharing technique shown above can’t work due to the mismatch in size of the
two tensors. What we need instead is to share part of the memory used by the two Buffers.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Network</span><span class="w"> </span><span class="n">net2</span><span class="p">;</span><span class="w">  </span><span class="c1">// Important: this has to be declared first, so it is destroyed after net1</span>
<span class="n">net2</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">&quot;nbg2.synap&quot;</span><span class="p">);</span><span class="w"></span>
<span class="n">Network</span><span class="w"> </span><span class="n">net1</span><span class="p">;</span><span class="w"></span>
<span class="n">net1</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">&quot;nbg1.synap&quot;</span><span class="p">);</span><span class="w"></span>

<span class="c1">// Initialize the entire destination tensor now that we still have CPU access to it</span>
<span class="n">memset</span><span class="p">(</span><span class="n">net2</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">net2</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">size</span><span class="p">());</span><span class="w"></span>

<span class="c1">// Replace net1 output buffer with a new one using (part of) the memory of net2 input buffer</span>
<span class="o">*</span><span class="n">net1</span><span class="p">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">buffer</span><span class="p">()</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Buffer</span><span class="p">(</span><span class="o">*</span><span class="n">net2</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">buffer</span><span class="p">(),</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">net2</span><span class="p">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">size</span><span class="p">());</span><span class="w"></span>

<span class="c1">// Disable CPU access for better performance</span>
<span class="n">net1</span><span class="p">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">buffer</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">allow_cpu_access</span><span class="p">(</span><span class="nb">false</span><span class="p">);</span><span class="w"></span>
<span class="n">net2</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">buffer</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">allow_cpu_access</span><span class="p">(</span><span class="nb">false</span><span class="p">);</span><span class="w"></span>

<span class="c1">// Do inference as usual</span>
<span class="n">custom_generate_input_data</span><span class="p">(</span><span class="n">net1</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">net1</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">size</span><span class="p">());</span><span class="w"></span>
<span class="n">net1</span><span class="p">.</span><span class="n">predict</span><span class="p">();</span><span class="w"></span>
<span class="n">net2</span><span class="p">.</span><span class="n">predict</span><span class="p">();</span><span class="w"></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Since net1 input tensor now uses the memory allocated by net2, it is important that net1 is destroyed
before net2, otherwise it will be left pointing to unallocated memory.
This limitation will be fixed in the next release.</p>
</div>
</section>
<section id="recycling-buffers">
<h3>Recycling Buffers<a class="headerlink" href="#recycling-buffers" title="Permalink to this headline"></a></h3>
<p>It is possible for the user to explicitly set at any time which buffer to use for each tensor
in a network. The cost of this operation is very low compared to the creation of a new buffer so
it is possible to change the buffer associated to a tensor at each inference if desired.</p>
<p>Despite this, the cost of <em>creating</em> a buffer and setting it to a tensor the first time is quite high
since it involves multiple memory allocations and validations. It is possible but deprecated to
create a new <code class="code docutils literal notranslate"><span class="pre">Buffer</span></code> at each inference, better to create the required buffers in advance
and then just use <code class="code docutils literal notranslate"><span class="pre">set_buffer()</span></code> to choose which one to use.</p>
<p>As an example consider a case where we want to do inference on the current data while at the same time
preparing the next data.
The following code shows how this can be done:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Network</span><span class="w"> </span><span class="n">net</span><span class="p">;</span><span class="w"></span>
<span class="n">net</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">&quot;model.synap&quot;</span><span class="p">);</span><span class="w"></span>

<span class="c1">// Create two input buffers</span>
<span class="k">const</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="n">input_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">net</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">size</span><span class="p">();</span><span class="w"></span>
<span class="n">vector</span><span class="o">&lt;</span><span class="n">Buffer</span><span class="o">&gt;</span><span class="w"> </span><span class="n">buffers</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">Buffer</span><span class="p">(</span><span class="n">input_size</span><span class="p">),</span><span class="w"> </span><span class="n">Buffer</span><span class="p">(</span><span class="n">input_size</span><span class="p">)</span><span class="w"> </span><span class="p">};</span><span class="w"></span>

<span class="kt">int</span><span class="w"> </span><span class="n">current</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="n">custom_start_generating_input_data</span><span class="p">(</span><span class="o">&amp;</span><span class="n">buffers</span><span class="p">[</span><span class="n">current</span><span class="p">]);</span><span class="w"></span>
<span class="k">while</span><span class="p">(</span><span class="nb">true</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">custom_wait_for_input_data</span><span class="p">();</span><span class="w"></span>

<span class="w">    </span><span class="c1">// Do inference on current data while filling the other buffer</span>
<span class="w">    </span><span class="n">net</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_buffer</span><span class="p">(</span><span class="o">&amp;</span><span class="n">buffers</span><span class="p">[</span><span class="n">current</span><span class="p">]);</span><span class="w"></span>
<span class="w">    </span><span class="n">current</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">!</span><span class="n">current</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">custom_start_generating_input_data</span><span class="p">(</span><span class="o">&amp;</span><span class="n">buffers</span><span class="p">[</span><span class="n">current</span><span class="p">]);</span><span class="w"></span>
<span class="w">    </span><span class="n">net</span><span class="p">.</span><span class="n">predict</span><span class="p">();</span><span class="w"></span>
<span class="w">    </span><span class="n">custom_process_result</span><span class="p">(</span><span class="n">net</span><span class="p">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</section>
<section id="using-buffercache">
<h3>Using BufferCache<a class="headerlink" href="#using-buffercache" title="Permalink to this headline"></a></h3>
<p>There are situations where the data to be processed comes form other components that
provide each time a data block taken from a fixed pool of blocks. Each block can be uniquely identified
by an ID or by an address. This is the case for example of a video pipeline providing frames.</p>
<p>Processing in this case should proceed as follows:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Get the next block to be processed</p></li>
<li><p>If this is the first time we see this block, create a new <code class="code docutils literal notranslate"><span class="pre">Buffer</span></code> for it and add it to a collection</p></li>
<li><p>Get the <code class="code docutils literal notranslate"><span class="pre">Buffer</span></code> corresponding to this block from the collection</p></li>
<li><p>Set is as the current buffer for the input tensor</p></li>
<li><p>Do inference and process the result</p></li>
</ol>
</div></blockquote>
<p>The collection is needed to avoid the expensive operation of creating a new <code class="code docutils literal notranslate"><span class="pre">Buffer</span></code> each time.
This is not complicate to code but steps 2 and 3 are always the same.
The <code class="code docutils literal notranslate"><span class="pre">BufferCache</span></code> template takes care of all this. The template parameter allows to specify
the type to be used to identify the received block, this can be for example a BlockID or directly
the address of the memory area.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In this case the buffer memory is not allocated by the <code class="code docutils literal notranslate"><span class="pre">Buffer</span></code> object.
The user is responsible for ensuring that all data is properly padded and aligned.
Futhermore the buffer cache is not taking ownership of the data block, it’s responsibility
of the user to deallocate them in due time after the <code class="code docutils literal notranslate"><span class="pre">BufferCache</span></code> has been deleted.</p>
</div>
</section>
<section id="copying-and-moving">
<h3>Copying And Moving<a class="headerlink" href="#copying-and-moving" title="Permalink to this headline"></a></h3>
<p><code class="code docutils literal notranslate"><span class="pre">Network</span></code>, <code class="code docutils literal notranslate"><span class="pre">Tensor</span></code> and <code class="code docutils literal notranslate"><span class="pre">Buffer</span></code> objects internally access to HW resources so
can’t be copied. For example:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Network</span><span class="w"> </span><span class="n">net1</span><span class="p">;</span><span class="w"></span>
<span class="n">net1</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">&quot;model.synap&quot;</span><span class="p">);</span><span class="w"></span>
<span class="n">Network</span><span class="w"> </span><span class="n">net2</span><span class="p">;</span><span class="w"></span>
<span class="n">net2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">net1</span><span class="p">;</span><span class="w">  </span><span class="c1">// ERROR, copying networks is not allowed</span>
</pre></div>
</div>
<p>However <code class="code docutils literal notranslate"><span class="pre">Network</span></code> and <code class="code docutils literal notranslate"><span class="pre">Buffer</span></code> objects can be moved since this has no overhead and
can be convenient when the point of creation is not the point of use. Example:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Network</span><span class="w"> </span><span class="nf">my_create_network</span><span class="p">(</span><span class="n">string</span><span class="w"> </span><span class="n">nb_name</span><span class="p">,</span><span class="w"> </span><span class="n">string</span><span class="w"> </span><span class="n">meta_name</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">Network</span><span class="w"> </span><span class="n">net</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">net</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">nb_name</span><span class="p">,</span><span class="w"> </span><span class="n">meta_name</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">net</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="kt">void</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">Network</span><span class="w"> </span><span class="n">network</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">my_create_network</span><span class="p">(</span><span class="s">&quot;model.synap&quot;</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="p">...</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>The same functionality is not available for <code class="code docutils literal notranslate"><span class="pre">Tensor</span></code> objects, they can exist only inside
their own Network.</p>
</section>
</section>
<section id="npu-locking">
<h2>NPU Locking<a class="headerlink" href="#npu-locking" title="Permalink to this headline"></a></h2>
<p>An application can decide to reserve the NPU for its exclusive usage. This can be useful
in case of realtime applications that have strict requirements in terms of latency, for example
video or audio stream processing.</p>
<p>Locking the NPU can be done at two levels:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>reserve NPU access to the current process using <code class="code docutils literal notranslate"><span class="pre">Npu::lock()</span></code></p></li>
<li><p>reserve NPU for <em>offline use only</em> (that is disable NPU access from NNAPI)</p></li>
</ol>
</div></blockquote>
<section id="id2">
<h3>NPU Locking<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h3>
<p>The NPU locking is done <strong>by process</strong>, this means that once the <code class="code docutils literal notranslate"><span class="pre">Npu::lock()</span></code> API
is called no other process will be able to run inference on the NPU.
Other processes will still be able to load networks, but if they try to do offline or online
NNAPI inference or to <code class="code docutils literal notranslate"><span class="pre">lock()</span></code> the NPU again, they will fail.</p>
<p>The process which has locked the NPU is the only one which has the righs to unlock it. If a process
with a different PID tries to unlock() the NPU, the operation will be ignored and have no effect.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>There is currently no way for a process to test if the NPU has been locked by some other
process. The only possibility is to try to lock() the NPU, if this operation fails it means
that the NPU is already locked by another process or unavailable due to some failure.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the process owning the NPU lock terminates or is terminated for any reason, the lock is
automatically released.</p>
</div>
</section>
<section id="nnapi-locking">
<h3>NNAPI Locking<a class="headerlink" href="#nnapi-locking" title="Permalink to this headline"></a></h3>
<p>A process can reserve the NPU for offline use only so that nobody will be able to run <em>online</em>
inference on the NPU via NNAPI.
Other processes will still be able to run <em>offline</em> inference on the NPU.
SyNAP has no dedicated API for this, NNAPI can be disabled by setting the property <code class="docutils literal notranslate"><span class="pre">vendor.NNAPI_SYNAP_DISABLE</span></code>
to 1 using the standard Android API <code class="docutils literal notranslate"><span class="pre">__system_property_set()</span></code> or <code class="docutils literal notranslate"><span class="pre">android::base::SetProperty()</span></code>.
Sample code in: <a class="reference external" href="https://android.googlesource.com/platform/system/core/+/master/toolbox/setprop.cpp">https://android.googlesource.com/platform/system/core/+/master/toolbox/setprop.cpp</a></p>
<p>See also: <a class="reference internal" href="nnapi.html#nnapi-locking"><span class="std std-ref">Disabling NPU Usage From NNAPI</span></a></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It will still be possible to perform online inference on the NPU using the <em>timvx</em> tflite delegate.</p>
</div>
</section>
<section id="description">
<h3>Description<a class="headerlink" href="#description" title="Permalink to this headline"></a></h3>
<p>The <code class="code docutils literal notranslate"><span class="pre">Npu</span></code> class controls the locking and unlocking of the NPU.
Normally only one object of this class needs to be created when the applicaton start and destroyed
when the application is going to terminate.</p>
<figure class="align-default" id="id8">
<p class="plantuml">
<a href="_images/plantuml-a7aec28bcbe7ba77d36ee770482f5bebf950854d.png"><img src="_images/plantuml-a7aec28bcbe7ba77d36ee770482f5bebf950854d.png" alt="skinparam monochrome true
skinparam handwritten false
class Npu {
    bool available()
    ..
    bool lock()
    bool unlock()
    bool is_locked()
}" style="width: 68.9px; height: 76.05px"/></a>
</p>
<figcaption>
<p><span class="caption-number">Figure 9 </span><span class="caption-text">Npu class</span><a class="headerlink" href="#id8" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<dl class="cpp class">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap3NpuE">
<span id="_CPPv3N9synaptics5synap3NpuE"></span><span id="_CPPv2N9synaptics5synap3NpuE"></span><span id="synaptics::synap::Npu"></span><span class="target" id="classsynaptics_1_1synap_1_1Npu"></span><span class="k"><span class="pre">class</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">synaptics</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">synap</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">Npu</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap3NpuE" title="Permalink to this definition"></a><br /></dt>
<dd><p>Reserve NPU usage. </p>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric" id="breathe-section-title-public-functions">Public Functions</p>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK9synaptics5synap3Npu9availableEv">
<span id="_CPPv3NK9synaptics5synap3Npu9availableEv"></span><span id="_CPPv2NK9synaptics5synap3Npu9availableEv"></span><span id="synaptics::synap::Npu::availableC"></span><span class="target" id="classsynaptics_1_1synap_1_1Npu_1a9b8af08c84002ce80db79bf7c3dfe0b2"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">available</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK9synaptics5synap3Npu9availableEv" title="Permalink to this definition"></a><br /></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>true if NPU successfully initialized. </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap3Npu4lockEv">
<span id="_CPPv3N9synaptics5synap3Npu4lockEv"></span><span id="_CPPv2N9synaptics5synap3Npu4lockEv"></span><span id="synaptics::synap::Npu::lock"></span><span class="target" id="classsynaptics_1_1synap_1_1Npu_1abde223cb8968835b7f8f060e505facc2"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">lock</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap3Npu4lockEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Lock exclusive right to perform inference for the current process. </p>
<p>All other processes attemping to execute inference will fail, including those using NNAPI. The lock will stay active until <a class="reference internal" href="#classsynaptics_1_1synap_1_1Npu_1ae399421ee39cae4df5ea44bd21e31254"><span class="std std-ref">unlock()</span></a> is called or the <a class="reference internal" href="#classsynaptics_1_1synap_1_1Npu"><span class="std std-ref">Npu</span></a> object is deleted. </p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>true if NPU successfully locked, false if NPU unavailable or locked by another process. Calling this method on an <a class="reference internal" href="#classsynaptics_1_1synap_1_1Npu"><span class="std std-ref">Npu</span></a> object that is already locked has no effect, just returns true </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap3Npu6unlockEv">
<span id="_CPPv3N9synaptics5synap3Npu6unlockEv"></span><span id="_CPPv2N9synaptics5synap3Npu6unlockEv"></span><span id="synaptics::synap::Npu::unlock"></span><span class="target" id="classsynaptics_1_1synap_1_1Npu_1ae399421ee39cae4df5ea44bd21e31254"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">unlock</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap3Npu6unlockEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>Release exclusive right to perform inference. </p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>true if success. Calling this method on an <a class="reference internal" href="#classsynaptics_1_1synap_1_1Npu"><span class="std std-ref">Npu</span></a> object that is not locked has no effect, just returns true </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK9synaptics5synap3Npu9is_lockedEv">
<span id="_CPPv3NK9synaptics5synap3Npu9is_lockedEv"></span><span id="_CPPv2NK9synaptics5synap3Npu9is_lockedEv"></span><span id="synaptics::synap::Npu::is_lockedC"></span><span class="target" id="classsynaptics_1_1synap_1_1Npu_1a1c6963b5102e0be81c6b875e63d130c9"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">is_locked</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK9synaptics5synap3Npu9is_lockedEv" title="Permalink to this definition"></a><br /></dt>
<dd><p>
Note: the only way to test if the NPU is locked by someone else is to try to <a class="reference internal" href="#classsynaptics_1_1synap_1_1Npu_1abde223cb8968835b7f8f060e505facc2"><span class="std std-ref">lock()</span></a> it. </p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>true if we currently own the NPU lock.</p>
</dd>
</dl>
</dd></dl>

</div>
<dl class="cpp struct">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap3Npu7PrivateE">
<span id="_CPPv3N9synaptics5synap3Npu7PrivateE"></span><span id="_CPPv2N9synaptics5synap3Npu7PrivateE"></span><span id="synaptics::synap::Npu::Private"></span><span class="target" id="structsynaptics_1_1synap_1_1Npu_1_1Private"></span><span class="k"><span class="pre">struct</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Private</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap3Npu7PrivateE" title="Permalink to this definition"></a><br /></dt>
<dd><p><a class="reference internal" href="#classsynaptics_1_1synap_1_1Npu"><span class="std std-ref">Npu</span></a> private implementation. </p>
</dd></dl>

</dd></dl>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="code docutils literal notranslate"><span class="pre">Npu</span></code> class uses the <em>RAII</em> technique, this means that when an object of this class is
destroyed and it was locking the NPU, the NPU is automatically unlocked. This helps ensure
that when a program terminates the NPU is in all cases unlocked.</p>
</div>
</section>
<section id="sample-usage">
<h3>Sample Usage<a class="headerlink" href="#sample-usage" title="Permalink to this headline"></a></h3>
<p>The following diagrams show some example use of the NPU locking API.</p>
<figure class="align-default" id="id9">
<p class="plantuml">
<a href="_images/plantuml-ec43601dd6102cd1d845c3d7ef6e87650f461549.png"><img src="_images/plantuml-ec43601dd6102cd1d845c3d7ef6e87650f461549.png" alt="skinparam monochrome true
skinparam handwritten false
hide footbox
box &quot;Process 1&quot; #WhiteSmoke
participant main
participant Npu
end box
box &quot;Process 2&quot; #LightGray
participant &quot;main &quot;
participant &quot;Npu &quot;
end box

main -&gt; Npu ++ : lock
return true
== NPU locked by Process 1 ==
&quot;main &quot; -&gt; &quot;Npu &quot; ++ : lock
return false
main -&gt; Npu ++ : is_locked
return true
&quot;main &quot; -&gt; &quot;Npu &quot; ++ : is_locked
return false
main -&gt; Npu ++ : unlock
return true
== NPU unlocked ==
&quot;main &quot; -&gt; &quot;Npu &quot; ++ : lock
return true
== NPU locked by Process 2 ==" style="width: 173.4px; height: 345.6px"/></a>
</p>
<figcaption>
<p><span class="caption-number">Figure 10 </span><span class="caption-text">Locking the NPU</span><a class="headerlink" href="#id9" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<figure class="align-default" id="id10">
<p class="plantuml">
<a href="_images/plantuml-ee333a8c50c66fab97c035f891a7d3360c7b0a3a.png"><img src="_images/plantuml-ee333a8c50c66fab97c035f891a7d3360c7b0a3a.png" alt="skinparam monochrome true
skinparam handwritten false
hide footbox
box &quot;Process 1&quot; #WhiteSmoke
participant main
participant Npu
participant Network
end box
box &quot;Process 2&quot; #LightGray
participant &quot;main &quot;
participant &quot;Network &quot;
end box
box &quot;Process 3&quot; #Silver
participant &quot; main&quot;
participant &quot;AndroidNNRuntime&quot;
end box

main -&gt; Npu ++ : lock
return true
== NPU locked by Process 1 ==
main -&gt; Network ++ : load
return true
main -&gt; Network ++ : predict
return true
&quot;main &quot; -&gt; &quot;Network &quot; ++ : load
return true
&quot;main &quot; -&gt; &quot;Network &quot; ++ : predict
note left of &quot;Network &quot; : inference from another process fails
return false
&quot; main&quot; -&gt; &quot;AndroidNNRuntime&quot; ++ : ANeuralNetworksExecution_startCompute
note left of AndroidNNRuntime: inference using NNAPI also fails
return ANEURALNETWORKS_OP_FAILED
main -&gt; Npu ++ : unlock
return true
== NPU unlocked ==
&quot;main &quot; -&gt; &quot;Network &quot; ++ : predict
return true" style="width: 439.8px; height: 438.0px"/></a>
</p>
<figcaption>
<p><span class="caption-number">Figure 11 </span><span class="caption-text">Locking and inference</span><a class="headerlink" href="#id10" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<figure class="align-default" id="id11">
<p class="plantuml">
<a href="_images/plantuml-0335724099570a21a849f2d6b9af4a026c632624.png"><img src="_images/plantuml-0335724099570a21a849f2d6b9af4a026c632624.png" alt="skinparam monochrome true
skinparam handwritten false
hide footbox
box &quot;Process 1&quot; #WhiteSmoke
participant main
participant Android
participant Network
end box
box &quot;Process 2&quot; #LightGray
participant &quot;main &quot;
participant &quot;Network &quot;
end box
box &quot;Process 3&quot; #Silver
participant &quot; main&quot;
participant &quot;AndroidNNRuntime&quot;
end box

main -&gt; Android ++ : setprop vendor.NNAPI_SYNAP_DISABLE 1
return true
== NNAPI locked by Process 1 ==
main -&gt; Network ++ : load
return true
main -&gt; Network ++ : predict
return true
&quot;main &quot; -&gt; &quot;Network &quot; ++ : load
return true
&quot;main &quot; -&gt; &quot;Network &quot; ++ : predict
note left of &quot;Network &quot; : inference from another process still allowed
return true
&quot; main&quot; -&gt; &quot;AndroidNNRuntime&quot; ++ : ANeuralNetworksExecution_startCompute
note left of AndroidNNRuntime: inference using NNAPI fails
return ANEURALNETWORKS_OP_FAILED
main -&gt; Android ++ : setprop vendor.NNAPI_SYNAP_DISABLE 0
return true
== NNAPI unlocked ==
&quot;main &quot; -&gt; &quot;Network &quot; ++ : predict
return true" style="width: 577.2px; height: 438.0px"/></a>
</p>
<figcaption>
<p><span class="caption-number">Figure 12 </span><span class="caption-text">Locking NNAPI</span><a class="headerlink" href="#id11" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<figure class="align-default" id="id12">
<p class="plantuml">
<a href="_images/plantuml-38e6b1ebc51c067727de9e9b47cd1e5ae05c5969.png"><img src="_images/plantuml-38e6b1ebc51c067727de9e9b47cd1e5ae05c5969.png" alt="skinparam monochrome true
skinparam handwritten false
hide footbox
box &quot;Process 1&quot; #WhiteSmoke
participant main
participant Npu
end box
box &quot;Process 2&quot; #LightGray
participant &quot;main &quot;
participant &quot;Network &quot;
end box
box &quot;Process 3&quot; #Silver
participant &quot; main&quot;
participant &quot;AndroidNNRuntime&quot;
end box

main -&gt; Npu ** : new
&quot;main &quot; -&gt; &quot;Network &quot; ++ : predict
return true
main -&gt; Npu ++ : lock
return true
== NPU locked by Process 1 ==
&quot;main &quot; -&gt; &quot;Network &quot; ++ : predict
return false
&quot; main&quot; -&gt; &quot;AndroidNNRuntime&quot; ++ : ANeuralNetworksExecution_startCompute
return ANEURALNETWORKS_OP_FAILED
main -&gt; Npu !! : delete
== NPU unlocked ==
main -&gt; main !! : exit
&quot;main &quot; -&gt; &quot;Network &quot; ++ : predict
return true
&quot; main&quot; -&gt; &quot;AndroidNNRuntime&quot; ++ : ANeuralNetworksExecution_startCompute
return ANEURALNETWORKS_NO_ERROR" style="width: 396.0px; height: 390.0px"/></a>
</p>
<figcaption>
<p><span class="caption-number">Figure 13 </span><span class="caption-text">Automatic lock release</span><a class="headerlink" href="#id12" title="Permalink to this image"></a></p>
</figcaption>
</figure>
</section>
</section>
<section id="preprocessing-and-postprocessing">
<h2>Preprocessing And Postprocessing<a class="headerlink" href="#preprocessing-and-postprocessing" title="Permalink to this headline"></a></h2>
<p>When using neural networks the input and output data are rarely used in their raw format.
Most often data conversion has to be performed on the input data in order make them match
the format expected by the network, this step is called <em>preprocessing</em>.</p>
<p>Example of preprocessing in the case of an image are:</p>
<ul class="simple">
<li><p>scale and/or crop the input image the the size expected by the network</p></li>
<li><p>convert planar to interleaved or vice-versa</p></li>
<li><p>convert RGB to BGR or vicerversa</p></li>
<li><p>apply mean and scale normalization</p></li>
</ul>
<p>These operations can be performed using the NPU at inference time by enabling preprocessing when
the model is converted using the SyNAP Toolkit, or they can be performed in SW when the data
is assigned to the Network.</p>
<p>Similarly the inference results contained in the network output tensor(s) normally
require further processing to make the result usable. This step is called <em>postprocessing</em>.
In some cases postprocessing can be a non-trivial step both in complexity and computation time.</p>
<p>Example of post-processing are:</p>
<ul class="simple">
<li><p>convert quantized data to floating point representation</p></li>
<li><p>analyze the network output to extract the most significant elements</p></li>
<li><p>combine the data from multiple output tensor to obtain a meaningful result</p></li>
</ul>
<p>The classes in this section are not part of the SyNAP API, they are intented mainly as utility
classes that can help writing SyNAP applications by combining the three usual steps of
preprocess-inference-postprocess just explained.</p>
<p>Full source code is provided, so they can be used as a reference implementation for the user to extend.</p>
<section id="inputdata-class">
<span id="id3"></span><h3>InputData Class<a class="headerlink" href="#inputdata-class" title="Permalink to this headline"></a></h3>
<p>The main role of the <code class="docutils literal notranslate"><span class="pre">InputData</span></code> class is to wrap the actual input data and complement it with additional
information to specify what the data represents and how it is organized.
The current implementation is mainly focused on image data.</p>
<p><code class="docutils literal notranslate"><span class="pre">InputData</span></code> functionality includes:</p>
<ul class="simple">
<li><p>reading raw files (binary)</p></li>
<li><p>reading and parsing images (jpeg or png) from file or memory</p></li>
<li><p>getting image attributes, e.g. dimensions and layout.</p></li>
</ul>
<p>The input filename is specified directly in the constructor and can’t be changed.
In alternative to a filename it is also possible to specify a memory address in case the content
is already available in memory.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>No data conversion is performed, even for jpeg or png images the data is kept in its original form.</p>
</div>
<figure class="align-default" id="id13">
<p class="plantuml">
<a href="_images/plantuml-1642958faf50e81103d31febb3416e7dbf0c32ec.png"><img src="_images/plantuml-1642958faf50e81103d31febb3416e7dbf0c32ec.png" alt="skinparam monochrome true
skinparam handwritten false
class InputData {
    InputData(filename)
    InputData(buffer, size, type, shape, layout)
    ..
    bool empty()
    void* data()
    size_t size()
    InputType type()
    Layout layout()
    Shape shape()
    Dimensions dimensions()
}" style="width: 153.4px; height: 118.95px"/></a>
</p>
<figcaption>
<p><span class="caption-number">Figure 14 </span><span class="caption-text">InputData class</span><a class="headerlink" href="#id13" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>Example:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Network</span><span class="w"> </span><span class="n">net</span><span class="p">;</span><span class="w"></span>
<span class="n">net</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">&quot;model.synap&quot;</span><span class="p">);</span><span class="w"></span>
<span class="n">InputData</span><span class="w"> </span><span class="nf">image</span><span class="p">(</span><span class="s">&quot;sample_rgb_image.dat&quot;</span><span class="p">);</span><span class="w"></span>
<span class="n">net</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">assign</span><span class="p">(</span><span class="n">image</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">image</span><span class="p">.</span><span class="n">size</span><span class="p">());</span><span class="w"></span>
<span class="n">net</span><span class="p">.</span><span class="n">predict</span><span class="p">();</span><span class="w"></span>
<span class="n">custom_process_result</span><span class="p">(</span><span class="n">net</span><span class="p">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span><span class="w"></span>
</pre></div>
</div>
</section>
<section id="preprocessor-class">
<h3>Preprocessor Class<a class="headerlink" href="#preprocessor-class" title="Permalink to this headline"></a></h3>
<p>This class takes in input an <code class="docutils literal notranslate"><span class="pre">InputData</span></code> object and assigns its content to the input Tensor(s)
of a network by performing all the necessary conversions.
The conversion(s) required are determined automatically by reading the attributes of the tensor itself.</p>
<p>Supported conversions include:</p>
<ul class="simple">
<li><p>image decoding (jpeg, png or nv21 to rgb)</p></li>
<li><p>layout conversion: <em>nchw</em> to <em>nhwc</em> or vice-versa</p></li>
<li><p>format conversion: <em>rgb</em> to <em>bgr</em> or <em>grayscale</em></p></li>
<li><p>image cropping (if preprocessing with cropping enabled in the compiled model)</p></li>
<li><p>image rescaling to fit the tensor dimensions</p></li>
</ul>
<p>The conversion (if needed) is performed when an <code class="docutils literal notranslate"><span class="pre">InputData</span></code> object is assigned to a <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>.</p>
<p>Cropping is only performed if enabled in the compiled model and the multi-tensor assign API is used:
<code class="docutils literal notranslate"><span class="pre">Preprocessor::assign(Tensors&amp;</span> <span class="pre">ts,</span> <span class="pre">const</span> <span class="pre">InputData&amp;</span> <span class="pre">data)</span></code>.</p>
<p>Rescaling by default preserves the aspect ratio of the input image.
If the destination tensor is taller than the rescaled input image, gray bands are added at the top
and bottom.
If the destination tensor is wider than then the rescaled input image, gray bands are added at the
left and right. It is possible to configure the gray level of the fill using the <code class="docutils literal notranslate"><span class="pre">fill_color=N</span></code> option
in the format string of the input tensor, where <cite>N</cite> is an integer between 0 (black) and 255 (white).</p>
<p>The preservation of the aspect-ratio can be disabled by specifying the <code class="docutils literal notranslate"><span class="pre">keep_proportions=0</span></code> option
in the format string of the input tensor. In this case the input image is simply resized to match
the size of the tensor.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Preprocessor</span></code>  class performs preprocessing using the CPU. If the conversion to be done
is known in advance it may be convenient to perform it using the NPU by adding
a preprocessing layer when the network is converted, see <a class="reference internal" href="working_with_models.html#preprocessing"><span class="std std-ref">Preprocessing</span></a></p>
</div>
</section>
<section id="imagepostprocessor-class">
<h3>ImagePostprocessor Class<a class="headerlink" href="#imagepostprocessor-class" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">ImagePostprocessor</span></code> functionality includes:</p>
<ul class="simple">
<li><p>reading the content of a set of Tensors</p></li>
<li><p>converting the raw content of the Tensors to a standard representation (currently only <code class="docutils literal notranslate"><span class="pre">nv21</span></code> is supported)
The format of the raw content is determined automatically by reading
the attributes of the tensors themselves. For example in some super-resolution network, the different
component of the output image (<em>y</em>, <em>uv</em>) are provided in separate outputs.
The converted data is made available in a standard vector.</p></li>
</ul>
<figure class="align-default" id="id14">
<p class="plantuml">
<a href="_images/plantuml-d75ed516fc79d792039fdc22916faf44ff20aebb.png"><img src="_images/plantuml-d75ed516fc79d792039fdc22916faf44ff20aebb.png" alt="skinparam monochrome true
skinparam handwritten false
class ImagePostprocessor {
    ImagePostprocessor()
    ..
    Result process(tensors)
}" style="width: 104.65px; height: 59.15px"/></a>
</p>
<figcaption>
<p><span class="caption-number">Figure 15 </span><span class="caption-text">ImagePostprocessor class</span><a class="headerlink" href="#id14" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>Example:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Preprocessor</span><span class="w"> </span><span class="n">preprocessor</span><span class="w"></span>
<span class="n">Network</span><span class="w"> </span><span class="n">net</span><span class="p">;</span><span class="w"></span>
<span class="n">ImagePostprocessor</span><span class="w"> </span><span class="n">postprocessor</span><span class="p">;</span><span class="w"></span>

<span class="n">net</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">&quot;model.synap&quot;</span><span class="p">);</span><span class="w"></span>
<span class="n">InputData</span><span class="w"> </span><span class="nf">image</span><span class="p">(</span><span class="s">&quot;sample_image.jpg&quot;</span><span class="p">);</span><span class="w"></span>
<span class="n">preprocessor</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="n">net</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="n">image</span><span class="p">);</span><span class="w"></span>
<span class="n">net</span><span class="p">.</span><span class="n">predict</span><span class="p">();</span><span class="w"></span>
<span class="c1">// Convert to nv21</span>
<span class="n">ImagePostprocessor</span><span class="o">::</span><span class="n">Result</span><span class="w"> </span><span class="n">out_image</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">postprocessor</span><span class="p">.</span><span class="n">process</span><span class="p">(</span><span class="n">net</span><span class="p">.</span><span class="n">outputs</span><span class="p">);</span><span class="w"></span>
<span class="n">binary_file_write</span><span class="p">(</span><span class="s">&quot;out_file.nv21&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">out_image</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">out_image</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">size</span><span class="p">());</span><span class="w"></span>
</pre></div>
</div>
</section>
<section id="classifier-class">
<h3>Classifier Class<a class="headerlink" href="#classifier-class" title="Permalink to this headline"></a></h3>
<p>The <code class="code docutils literal notranslate"><span class="pre">Classifier</span></code> class is a postprocessor for the common use case of image
classification networks.</p>
<p>There are just two things that can be done with a classifier:</p>
<blockquote>
<div><ul class="simple">
<li><p>initialize it</p></li>
<li><p>process network outputs: this will return a list of possible classifications sorted in order
of decreasing confidence, each containing the following information:</p>
<ul>
<li><p>class_index</p></li>
<li><p>confidence</p></li>
</ul>
</li>
</ul>
</div></blockquote>
<figure class="align-default" id="id15">
<p class="plantuml">
<a href="_images/plantuml-8a5bba4cf59003d49adafba0cc27e8853b9ef932.png"><img src="_images/plantuml-8a5bba4cf59003d49adafba0cc27e8853b9ef932.png" alt="skinparam monochrome true
skinparam handwritten false
class Classifier {
    Classifier(top_count)
    Result process(tensors)
}" style="width: 96.2px; height: 59.15px"/></a>
</p>
<figcaption>
<p><span class="caption-number">Figure 16 </span><span class="caption-text">Classifier class</span><a class="headerlink" href="#id15" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<dl class="cpp class">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap10ClassifierE">
<span id="_CPPv3N9synaptics5synap10ClassifierE"></span><span id="_CPPv2N9synaptics5synap10ClassifierE"></span><span id="synaptics::synap::Classifier"></span><span class="target" id="classsynaptics_1_1synap_1_1Classifier"></span><span class="k"><span class="pre">class</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">synaptics</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">synap</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">Classifier</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap10ClassifierE" title="Permalink to this definition"></a><br /></dt>
<dd><p>Classification post-processor for <a class="reference internal" href="#classsynaptics_1_1synap_1_1Network"><span class="std std-ref">Network</span></a> output tensors. </p>
<p>Determine the top-N classifications of an image. </p>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric" id="breathe-section-title-public-functions">Public Functions</p>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap10Classifier10ClassifierE6size_t">
<span id="_CPPv3N9synaptics5synap10Classifier10ClassifierE6size_t"></span><span id="_CPPv2N9synaptics5synap10Classifier10ClassifierE6size_t"></span><span id="synaptics::synap::Classifier::Classifier__s"></span><span class="target" id="classsynaptics_1_1synap_1_1Classifier_1afc77e451073c656cc95879d5c39da5b6"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Classifier</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">size_t</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">top_count</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">1</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap10Classifier10ClassifierE6size_t" title="Permalink to this definition"></a><br /></dt>
<dd><p>Constructor. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>top_count</strong> – number of most probable classifications to return </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap10Classifier7processERK7Tensors">
<span id="_CPPv3N9synaptics5synap10Classifier7processERK7Tensors"></span><span id="_CPPv2N9synaptics5synap10Classifier7processERK7Tensors"></span><span id="synaptics::synap::Classifier::process__TensorsCR"></span><span class="target" id="classsynaptics_1_1synap_1_1Classifier_1aff4856d94741fefd1b22a1a2929ab94c"></span><a class="reference internal" href="#_CPPv4N9synaptics5synap10Classifier6ResultE" title="synaptics::synap::Classifier::Result"><span class="n"><span class="pre">Result</span></span></a><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">process</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">Tensors</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">tensors</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap10Classifier7processERK7Tensors" title="Permalink to this definition"></a><br /></dt>
<dd><p>Perform classification on network output tensors. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensors</strong> – output tensors of the network tensors[0] is expected to contain a list of confidences, one for each image class </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>classification results </p>
</dd>
</dl>
</dd></dl>

</div>
<dl class="cpp struct">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap10Classifier6ResultE">
<span id="_CPPv3N9synaptics5synap10Classifier6ResultE"></span><span id="_CPPv2N9synaptics5synap10Classifier6ResultE"></span><span id="synaptics::synap::Classifier::Result"></span><span class="target" id="structsynaptics_1_1synap_1_1Classifier_1_1Result"></span><span class="k"><span class="pre">struct</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Result</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap10Classifier6ResultE" title="Permalink to this definition"></a><br /></dt>
<dd><p>Classification result. </p>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric" id="breathe-section-title-public-members">Public Members</p>
<dl class="cpp var">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap10Classifier6Result7successE">
<span id="_CPPv3N9synaptics5synap10Classifier6Result7successE"></span><span id="_CPPv2N9synaptics5synap10Classifier6Result7successE"></span><span id="synaptics::synap::Classifier::Result::success__b"></span><span class="target" id="structsynaptics_1_1synap_1_1Classifier_1_1Result_1a7960f9c558f9ee2c3d4a8fdea096fb56"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">success</span></span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="p"><span class="pre">{</span></span><span class="p"><span class="pre">}</span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap10Classifier6Result7successE" title="Permalink to this definition"></a><br /></dt>
<dd><p>True if classification successful, false if failed. </p>
</dd></dl>

<dl class="cpp var">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap10Classifier6Result5itemsE">
<span id="_CPPv3N9synaptics5synap10Classifier6Result5itemsE"></span><span id="_CPPv2N9synaptics5synap10Classifier6Result5itemsE"></span><span id="synaptics::synap::Classifier::Result::items__std::vector:Item:"></span><span class="target" id="structsynaptics_1_1synap_1_1Classifier_1_1Result_1a35e360a464709adff5606088ca07c8db"></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">vector</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="#_CPPv4N9synaptics5synap10Classifier6Result4ItemE" title="synaptics::synap::Classifier::Result::Item"><span class="n"><span class="pre">Item</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">items</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap10Classifier6Result5itemsE" title="Permalink to this definition"></a><br /></dt>
<dd><p>List of possible classifications for the input, sorted in descending confidence order, that is items[0] is the classification with the highest confidence. </p>
<p>Empty if classification failed. </p>
</dd></dl>

</div>
<dl class="cpp struct">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap10Classifier6Result4ItemE">
<span id="_CPPv3N9synaptics5synap10Classifier6Result4ItemE"></span><span id="_CPPv2N9synaptics5synap10Classifier6Result4ItemE"></span><span id="synaptics::synap::Classifier::Result::Item"></span><span class="target" id="structsynaptics_1_1synap_1_1Classifier_1_1Result_1_1Item"></span><span class="k"><span class="pre">struct</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Item</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap10Classifier6Result4ItemE" title="Permalink to this definition"></a><br /></dt>
<dd><p>Classification item. </p>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric" id="breathe-section-title-public-members">Public Members</p>
<dl class="cpp var">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap10Classifier6Result4Item11class_indexE">
<span id="_CPPv3N9synaptics5synap10Classifier6Result4Item11class_indexE"></span><span id="_CPPv2N9synaptics5synap10Classifier6Result4Item11class_indexE"></span><span id="synaptics::synap::Classifier::Result::Item::class_index__int32_t"></span><span class="target" id="structsynaptics_1_1synap_1_1Classifier_1_1Result_1_1Item_1a0f1d7fe1f7a6a74b9ba374f3d91be8b5"></span><span class="n"><span class="pre">int32_t</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">class_index</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap10Classifier6Result4Item11class_indexE" title="Permalink to this definition"></a><br /></dt>
<dd><p>Index of the class. </p>
</dd></dl>

<dl class="cpp var">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap10Classifier6Result4Item10confidenceE">
<span id="_CPPv3N9synaptics5synap10Classifier6Result4Item10confidenceE"></span><span id="_CPPv2N9synaptics5synap10Classifier6Result4Item10confidenceE"></span><span id="synaptics::synap::Classifier::Result::Item::confidence__float"></span><span class="target" id="structsynaptics_1_1synap_1_1Classifier_1_1Result_1_1Item_1a058b8558da894ebfbef73d1a9b57deaa"></span><span class="kt"><span class="pre">float</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">confidence</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap10Classifier6Result4Item10confidenceE" title="Permalink to this definition"></a><br /></dt>
<dd><p>Confidence of the classification, normally in the range [0, 1]. </p>
</dd></dl>

</div>
</dd></dl>

</dd></dl>

</dd></dl>

<p>Example:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Preprocessor</span><span class="w"> </span><span class="n">preprocessor</span><span class="w"></span>
<span class="n">Network</span><span class="w"> </span><span class="n">net</span><span class="p">;</span><span class="w"></span>
<span class="n">Classifier</span><span class="w"> </span><span class="nf">classifier</span><span class="p">(</span><span class="mi">5</span><span class="p">);</span><span class="w"></span>
<span class="n">net</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">&quot;model.synap&quot;</span><span class="p">);</span><span class="w"></span>
<span class="n">InputData</span><span class="w"> </span><span class="nf">image</span><span class="p">(</span><span class="s">&quot;sample_image.jpg&quot;</span><span class="p">);</span><span class="w"></span>
<span class="n">preprocessor</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="n">net</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="n">image</span><span class="p">);</span><span class="w"></span>
<span class="n">net</span><span class="p">.</span><span class="n">predict</span><span class="p">();</span><span class="w"></span>
<span class="n">Classifier</span><span class="o">::</span><span class="n">Result</span><span class="w"> </span><span class="n">top5</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">classifier</span><span class="p">.</span><span class="n">process</span><span class="p">(</span><span class="n">net</span><span class="p">.</span><span class="n">outputs</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
<p>The standard content of the output tensor of a classification network is a list of probabilities,
one for each class on which the model has been trained (possibly including an initial element to
indicate a “background” or “unrecognized” class). In some cases the final <em>SoftMax</em> layer of the
model is cut away to improve inference time: in this case the output values can’t be interpreted
as probabilities anymore but since <em>SoftMax</em> is monotonic this doesn’t change the result of the
classification.
The postprocessing can be parametrized using the <em>format</em> field of the corresponding
output in the conversion metafile (see <a class="reference internal" href="working_with_models.html#conversion-metafile"><span class="std std-ref">Conversion Metafile</span></a>):</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 34%" />
<col style="width: 7%" />
<col style="width: 15%" />
<col style="width: 45%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Format Type</p></th>
<th class="head"><p>Out#</p></th>
<th class="head"><p>Shape</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>confidence_array</p></td>
<td><p>0</p></td>
<td><p>NxC</p></td>
<td><p>List of probabilities, one per class</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 28%" />
<col style="width: 8%" />
<col style="width: 64%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Attribute</p></th>
<th class="head"><p>Default</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>class_index_base</p></td>
<td><p>0</p></td>
<td><p>Class index corresponding to the first element of the output vector</p></td>
</tr>
</tbody>
</table>
<p>Where:</p>
<blockquote>
<div><ul class="simple">
<li><p>N: Number of samples, must be 1</p></li>
<li><p>C: number of recognized classes</p></li>
</ul>
</div></blockquote>
</section>
<section id="detector-class">
<h3>Detector Class<a class="headerlink" href="#detector-class" title="Permalink to this headline"></a></h3>
<p>The <code class="code docutils literal notranslate"><span class="pre">Detector</span></code> class is a postprocessor for the common use case of object detection networks.
Here <em>object</em> is a generic term that can refer to actual objects or people or anything used to
train the network.</p>
<p>There are just two things that can be done with a detector:</p>
<blockquote>
<div><ul class="simple">
<li><p>initialize it</p></li>
<li><p>run a detection: this will return a list of detection items, each containing
the following information:</p>
<ul>
<li><p>class_index</p></li>
<li><p>confidence</p></li>
<li><p>bounding box</p></li>
<li><p>landmarks (optional)</p></li>
</ul>
</li>
</ul>
</div></blockquote>
<figure class="align-default" id="id16">
<p class="plantuml">
<a href="_images/plantuml-b314e00b4ced69edd39ad4ec16ba60b119cb6a6e.png"><img src="_images/plantuml-b314e00b4ced69edd39ad4ec16ba60b119cb6a6e.png" alt="skinparam monochrome true
skinparam handwritten false
class Detector {
    Detector(threshold, n_max, nms, iou_threshold, iou_with_min)
    Result process(tensors, input_rect)
}" style="width: 213.85px; height: 59.15px"/></a>
</p>
<figcaption>
<p><span class="caption-number">Figure 17 </span><span class="caption-text">Detector class</span><a class="headerlink" href="#id16" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<dl class="cpp class">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8DetectorE">
<span id="_CPPv3N9synaptics5synap8DetectorE"></span><span id="_CPPv2N9synaptics5synap8DetectorE"></span><span id="synaptics::synap::Detector"></span><span class="target" id="classsynaptics_1_1synap_1_1Detector"></span><span class="k"><span class="pre">class</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">synaptics</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">synap</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">Detector</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap8DetectorE" title="Permalink to this definition"></a><br /></dt>
<dd><p>Object-detector. </p>
<p>The output format of object-detection networks is not always the same but depends on the network architecture used. The format type must be specified in the <em>format</em> field of the output tensor in the network metafile when the network is compiled. This following formats are currently supported: “retinanet_boxes”, “tflite_detection_boxes”, “yolov5” </p>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric" id="breathe-section-title-public-functions">Public Functions</p>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8Detector8DetectorEfibfb">
<span id="_CPPv3N9synaptics5synap8Detector8DetectorEfibfb"></span><span id="_CPPv2N9synaptics5synap8Detector8DetectorEfibfb"></span><span id="synaptics::synap::Detector::Detector__float.i.b.float.b"></span><span class="target" id="classsynaptics_1_1synap_1_1Detector_1afa078f406ebe9829a6d1230458e0ce51"></span><span class="sig-name descname"><span class="n"><span class="pre">Detector</span></span></span><span class="sig-paren">(</span><span class="kt"><span class="pre">float</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">score_threshold</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">0.5</span></span>, <span class="kt"><span class="pre">int</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">n_max</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">0</span></span>, <span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">nms</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">true</span></span>, <span class="kt"><span class="pre">float</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">iou_threshold</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">.5</span></span>, <span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">iou_with_min</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">false</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap8Detector8DetectorEfibfb" title="Permalink to this definition"></a><br /></dt>
<dd><p>Constructor. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>score_threshold</strong> – detections below this score are discarded </p></li>
<li><p><strong>n_max</strong> – max number of detections (0: all) </p></li>
<li><p><strong>nms</strong> – if true apply non-max-suppression to remove duplicate detections </p></li>
<li><p><strong>iou_threshold</strong> – intersection-over-union threshold (used if nms is true) </p></li>
<li><p><strong>iou_with_min</strong> – use min area instead of union to compute intersection-over-union </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8Detector4initERK7Tensors">
<span id="_CPPv3N9synaptics5synap8Detector4initERK7Tensors"></span><span id="_CPPv2N9synaptics5synap8Detector4initERK7Tensors"></span><span id="synaptics::synap::Detector::init__TensorsCR"></span><span class="target" id="classsynaptics_1_1synap_1_1Detector_1aa8e8cfe9c5d9e17774fc22acf6f2ac95"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">init</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">Tensors</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">tensors</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap8Detector4initERK7Tensors" title="Permalink to this definition"></a><br /></dt>
<dd><p>Initialize detector. </p>
<p>If not called the detector is automatically initialized the 1st time <a class="reference internal" href="#classsynaptics_1_1synap_1_1Detector_1a53e633cff42e88ee806e0e6f4412d223"><span class="std std-ref">process()</span></a> is called.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensors</strong> – output tensors of the network (after the network has been loaded) </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>true if success </p>
</dd>
</dl>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8Detector7processERK7TensorsRK4Rect">
<span id="_CPPv3N9synaptics5synap8Detector7processERK7TensorsRK4Rect"></span><span id="_CPPv2N9synaptics5synap8Detector7processERK7TensorsRK4Rect"></span><span id="synaptics::synap::Detector::process__TensorsCR.RectCR"></span><span class="target" id="classsynaptics_1_1synap_1_1Detector_1a53e633cff42e88ee806e0e6f4412d223"></span><a class="reference internal" href="#_CPPv4N9synaptics5synap8Detector6ResultE" title="synaptics::synap::Detector::Result"><span class="n"><span class="pre">Result</span></span></a><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">process</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">Tensors</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">tensors</span></span>, <span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">Rect</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">input_rect</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N9synaptics5synap8Detector7processERK7TensorsRK4Rect" title="Permalink to this definition"></a><br /></dt>
<dd><p>Perform detection on network output tensors. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensors</strong> – output tensors of the network </p></li>
<li><p><strong>input_rect</strong> – coordinates of the (sub)image provided in input (to compute bounding-boxes) </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>detection results </p>
</dd>
</dl>
</dd></dl>

</div>
<dl class="cpp class">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8Detector4ImplE">
<span id="_CPPv3N9synaptics5synap8Detector4ImplE"></span><span id="_CPPv2N9synaptics5synap8Detector4ImplE"></span><span id="synaptics::synap::Detector::Impl"></span><span class="target" id="classsynaptics_1_1synap_1_1Detector_1_1Impl"></span><span class="k"><span class="pre">class</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Impl</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap8Detector4ImplE" title="Permalink to this definition"></a><br /></dt>
<dd><p>Subclassed by DetectorBoxesScores, DetectorTfliteODPostprocessOut, DetectorYoloBase, DetectorYolov5Pyramid</p>
</dd></dl>

<dl class="cpp struct">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8Detector6ResultE">
<span id="_CPPv3N9synaptics5synap8Detector6ResultE"></span><span id="_CPPv2N9synaptics5synap8Detector6ResultE"></span><span id="synaptics::synap::Detector::Result"></span><span class="target" id="structsynaptics_1_1synap_1_1Detector_1_1Result"></span><span class="k"><span class="pre">struct</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Result</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap8Detector6ResultE" title="Permalink to this definition"></a><br /></dt>
<dd><p>Object-detector result. </p>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric" id="breathe-section-title-public-members">Public Members</p>
<dl class="cpp var">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8Detector6Result7successE">
<span id="_CPPv3N9synaptics5synap8Detector6Result7successE"></span><span id="_CPPv2N9synaptics5synap8Detector6Result7successE"></span><span id="synaptics::synap::Detector::Result::success__b"></span><span class="target" id="structsynaptics_1_1synap_1_1Detector_1_1Result_1a7960f9c558f9ee2c3d4a8fdea096fb56"></span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">success</span></span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="p"><span class="pre">{</span></span><span class="p"><span class="pre">}</span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap8Detector6Result7successE" title="Permalink to this definition"></a><br /></dt>
<dd><p>True if detection successful, false if detection failed. </p>
</dd></dl>

<dl class="cpp var">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8Detector6Result5itemsE">
<span id="_CPPv3N9synaptics5synap8Detector6Result5itemsE"></span><span id="_CPPv2N9synaptics5synap8Detector6Result5itemsE"></span><span id="synaptics::synap::Detector::Result::items__std::vector:Item:"></span><span class="target" id="structsynaptics_1_1synap_1_1Detector_1_1Result_1a35e360a464709adff5606088ca07c8db"></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">vector</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="#_CPPv4N9synaptics5synap8Detector6Result4ItemE" title="synaptics::synap::Detector::Result::Item"><span class="n"><span class="pre">Item</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">items</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap8Detector6Result5itemsE" title="Permalink to this definition"></a><br /></dt>
<dd><p>One entry for each detection. </p>
<p>Empty if nothing detected or detection failed. </p>
</dd></dl>

</div>
<dl class="cpp struct">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8Detector6Result4ItemE">
<span id="_CPPv3N9synaptics5synap8Detector6Result4ItemE"></span><span id="_CPPv2N9synaptics5synap8Detector6Result4ItemE"></span><span id="synaptics::synap::Detector::Result::Item"></span><span class="target" id="structsynaptics_1_1synap_1_1Detector_1_1Result_1_1Item"></span><span class="k"><span class="pre">struct</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Item</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap8Detector6Result4ItemE" title="Permalink to this definition"></a><br /></dt>
<dd><p>Detection item. </p>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric" id="breathe-section-title-public-members">Public Members</p>
<dl class="cpp var">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8Detector6Result4Item11class_indexE">
<span id="_CPPv3N9synaptics5synap8Detector6Result4Item11class_indexE"></span><span id="_CPPv2N9synaptics5synap8Detector6Result4Item11class_indexE"></span><span id="synaptics::synap::Detector::Result::Item::class_index__int32_t"></span><span class="target" id="structsynaptics_1_1synap_1_1Detector_1_1Result_1_1Item_1a0f1d7fe1f7a6a74b9ba374f3d91be8b5"></span><span class="n"><span class="pre">int32_t</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">class_index</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap8Detector6Result4Item11class_indexE" title="Permalink to this definition"></a><br /></dt>
<dd><p>Index of the object class. </p>
</dd></dl>

<dl class="cpp var">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8Detector6Result4Item10confidenceE">
<span id="_CPPv3N9synaptics5synap8Detector6Result4Item10confidenceE"></span><span id="_CPPv2N9synaptics5synap8Detector6Result4Item10confidenceE"></span><span id="synaptics::synap::Detector::Result::Item::confidence__float"></span><span class="target" id="structsynaptics_1_1synap_1_1Detector_1_1Result_1_1Item_1a058b8558da894ebfbef73d1a9b57deaa"></span><span class="kt"><span class="pre">float</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">confidence</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap8Detector6Result4Item10confidenceE" title="Permalink to this definition"></a><br /></dt>
<dd><p>Confidence of the detection in the range [0, 1]. </p>
</dd></dl>

<dl class="cpp var">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8Detector6Result4Item12bounding_boxE">
<span id="_CPPv3N9synaptics5synap8Detector6Result4Item12bounding_boxE"></span><span id="_CPPv2N9synaptics5synap8Detector6Result4Item12bounding_boxE"></span><span id="synaptics::synap::Detector::Result::Item::bounding_box__Rect"></span><span class="target" id="structsynaptics_1_1synap_1_1Detector_1_1Result_1_1Item_1a854a10d81326d5a4530face4176dece6"></span><span class="n"><span class="pre">Rect</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">bounding_box</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap8Detector6Result4Item12bounding_boxE" title="Permalink to this definition"></a><br /></dt>
<dd><p>Top,left corner plus horizontal and vertical size (in pixels) </p>
</dd></dl>

<dl class="cpp var">
<dt class="sig sig-object cpp" id="_CPPv4N9synaptics5synap8Detector6Result4Item9landmarksE">
<span id="_CPPv3N9synaptics5synap8Detector6Result4Item9landmarksE"></span><span id="_CPPv2N9synaptics5synap8Detector6Result4Item9landmarksE"></span><span id="synaptics::synap::Detector::Result::Item::landmarks__std::vector:Landmark:"></span><span class="target" id="structsynaptics_1_1synap_1_1Detector_1_1Result_1_1Item_1a1b0ffaa022c23c3f8389c6d7c2bdf687"></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">vector</span></span><span class="p"><span class="pre">&lt;</span></span><span class="n"><span class="pre">Landmark</span></span><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">landmarks</span></span></span><a class="headerlink" href="#_CPPv4N9synaptics5synap8Detector6Result4Item9landmarksE" title="Permalink to this definition"></a><br /></dt>
<dd><p>One entry for each landmark. </p>
<p>Empty if no landmark available. </p>
</dd></dl>

</div>
</dd></dl>

</dd></dl>

</dd></dl>

<p>Example:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Preprocessor</span><span class="w"> </span><span class="n">preprocessor</span><span class="w"></span>
<span class="n">Network</span><span class="w"> </span><span class="n">net</span><span class="p">;</span><span class="w"></span>
<span class="n">Detector</span><span class="w"> </span><span class="n">detector</span><span class="p">;</span><span class="w"></span>
<span class="n">net</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">&quot;model.synap&quot;</span><span class="p">);</span><span class="w"></span>
<span class="n">InputData</span><span class="w"> </span><span class="nf">image</span><span class="p">(</span><span class="s">&quot;sample_image.jpg&quot;</span><span class="p">);</span><span class="w"></span>
<span class="n">Rect</span><span class="w"> </span><span class="n">image_rect</span><span class="p">;</span><span class="w"></span>
<span class="n">preprocessor</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="n">net</span><span class="p">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="n">image</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">image_rect</span><span class="p">);</span><span class="w"></span>
<span class="n">net</span><span class="p">.</span><span class="n">predict</span><span class="p">();</span><span class="w"></span>
<span class="n">Detector</span><span class="o">::</span><span class="n">Result</span><span class="w"> </span><span class="n">objects</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">detector</span><span class="p">.</span><span class="n">process</span><span class="p">(</span><span class="n">net</span><span class="p">.</span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">image_rect</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
<p>The rectangle argument passed to the <code class="docutils literal notranslate"><span class="pre">process()</span></code> method is needed so that is can compute
bounding boxes and landmarks in coordinates relative to the original image, even if the image
has been resized and/or cropped during the assignment to the network input tensor.</p>
<p>Postprocessing consist of the following steps:</p>
<blockquote>
<div><ul class="simple">
<li><p>for each possible position in the input grid compute the score of the highest class there</p></li>
<li><p>if this score is too low nothing is detected at that position</p></li>
<li><p>if above the detection threshold then there is something there, so compute the actual bounding
box of the object by combining information about the anchors location, the regressed deltas
from the network and the actual size of the input image</p></li>
<li><p>once all the detections have been computed, filter them using Non-Min-Suppression algorithm
to discard spurious overlapping detections and keep only the one with highest score at each position.
The NMS filter applies only for bounding boxes which have an overlap above a minimum threshold.
The overlap itself is computed using the <em>IntersectionOverUnion</em> formula
(ref: <a class="reference external" href="https://medium.com/analytics-vidhya/iou-intersection-over-union-705a39e7acef">https://medium.com/analytics-vidhya/iou-intersection-over-union-705a39e7acef</a>).
In order to provide more filtering for boxes of different sizes, the “intersection” area
is sometimes replaced by the “minimum” area in the computation. SyNAP Detector implements both formula.</p></li>
</ul>
</div></blockquote>
<p>The content of the output tensor(s) from an object detection network is not standardized.
Several formats exist for the major families of detection networks, with variants inside each family.
The information contained is basically always the same, what changes is the way they are organized.
The <code class="docutils literal notranslate"><span class="pre">Detector</span></code> class currently supports the following output formats:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">retinanet_boxes</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tflite_detection_input</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tflite_detection</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">yolov5</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">yolov8</span></code></p></li>
</ul>
</div></blockquote>
<p>The desired label from the above list has to be put in the “format” field of the first output tensor of the
network in the conversion metafile (see <a class="reference internal" href="working_with_models.html#conversion-metafile"><span class="std std-ref">Conversion Metafile</span></a>) so the <code class="docutils literal notranslate"><span class="pre">Detector</span></code> knows how to interpret the output.</p>
<p><code class="docutils literal notranslate"><span class="pre">retinanet_boxes</span></code> is the output format used by Synaptics sample detection networks
(mobilenet224_full80 for COCO detection and mobilenet224_full1 for people detection).</p>
<p><code class="docutils literal notranslate"><span class="pre">tflite_detection_input</span></code> is the format of the input tensors of the <code class="docutils literal notranslate"><span class="pre">TFLite_Detection_PostProcess</span></code>
layer, used for example in the  <cite>ssd_mobilenet_v1_1_default_1.tflite</cite> object-detection model:</p>
<blockquote>
<div><p><a class="reference external" href="https://tfhub.dev/tensorflow/lite-model/ssd_mobilenet_v1/1/default/1">https://tfhub.dev/tensorflow/lite-model/ssd_mobilenet_v1/1/default/1</a></p>
</div></blockquote>
<p>This format is used when the <code class="docutils literal notranslate"><span class="pre">TFLite_Detection_PostProcess</span></code> layer is removed from the network at
conversion time and the corresponding postprocessing algorithm is performed in software.</p>
<p>In both cases above the model has two output tensors: the first one is a regression tensor, and contains
the bounding box deltas for the highest-score detected object in each position of the input grid. The second one
is the classification tensor and for each class contains the score of that class, that is the confidence
that this class is contained in the corresponding position of the input grid.</p>
<p><code class="docutils literal notranslate"><span class="pre">tflite_detection</span></code> is the format of the <em>output</em> tensors of the <code class="docutils literal notranslate"><span class="pre">TFLite_Detection_PostProcess</span></code>
layer, used for example in the  <cite>ssd_mobilenet_v1_1_default_1.tflite</cite> object-detection model.</p>
<p><code class="docutils literal notranslate"><span class="pre">yolov5</span></code> is the output format used by models derived from the well-kown <em>yolov5</em> arcitecture.
In this case the model has a single output 3D tensor organized as a list of detections, where each
detection contains the following fields:</p>
<blockquote>
<div><ul class="simple">
<li><p>bounding box deltas (x, y, w, h)</p></li>
<li><p>overall confidence for this detection</p></li>
<li><p>landmarks deltas (x, y) if supported by the model</p></li>
<li><p>confidence vector, one entry per class</p></li>
</ul>
</div></blockquote>
<p><code class="docutils literal notranslate"><span class="pre">yolov8</span></code> is the output format used by models derived from the <em>yolov8</em> arcitecture, the most recent
update to the <em>yolo</em> family. The organization of the output tensor is very similar to that for
yolov5 here above, the only difference is that the <em>overall confidence</em> field is missing.</p>
<p>In some cases the final layers in the model can be executed more efficiently in the CPU, so they are
cut away when the model is generated or compiled with the SyNAP Toolkit. In this case the network
will have one output tensor for each item of the image pyramid (normally 3) and each output will
be a 4D or 5D tensor, whose layout depends on where exacly the model has been cut.</p>
<p>SyNAP Detector is able to automatically deduce the layout used, it just requires an indication
if the information in the tensor are transposed.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 27%" />
<col style="width: 5%" />
<col style="width: 12%" />
<col style="width: 31%" />
<col style="width: 26%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Format Type</p></th>
<th class="head"><p>Out#</p></th>
<th class="head"><p>Shape</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Notes</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td rowspan="2"><p>retinanet_boxes</p></td>
<td><p>0</p></td>
<td><p>Nx4</p></td>
<td><p>bounding box deltas</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>NxC</p></td>
<td><p>Per-class probability</p></td>
<td></td>
</tr>
<tr class="row-even"><td rowspan="2"><p>tflite_detection_input</p>
<p>tflite_detection_boxes</p>
</td>
<td><p>0</p></td>
<td><p>Nx4</p></td>
<td><p>bounding box deltas</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>NxC</p></td>
<td><p>Per-class probability</p></td>
<td></td>
</tr>
<tr class="row-even"><td rowspan="4"><p>tflite_detection</p></td>
<td><p>0</p></td>
<td><p>NxMx4</p></td>
<td><p>Bounding boxes</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>NxM</p></td>
<td><p>Index of detected class</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>NxM</p></td>
<td><p>Score of detected class</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>1</p></td>
<td><p>Actual number of detections</p></td>
<td></td>
</tr>
<tr class="row-even"><td rowspan="6"><p>yolov5</p></td>
<td rowspan="6"><p>0..P-1</p></td>
<td><p>NxTxD</p></td>
<td><p>Processing done in the model</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>NxHxWxAxD</p></td>
<td><p>One 5D tensor per pyramid element</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>NxHxWx(A*D)</p></td>
<td><p>One 4D tensor per pyramid element</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>NxAxHxWxD</p></td>
<td><p>One 5D tensor per pyramid element</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>NxAxDxHxW</p></td>
<td><p>One 5D tensor per pyramid element</p></td>
<td><p>Requires “<code class="docutils literal notranslate"><span class="pre">transposed=1</span></code>”</p></td>
</tr>
<tr class="row-odd"><td><p>Nx(A*D)xHxW</p></td>
<td><p>One 4D tensor per pyramid element</p></td>
<td><p>Requires “<code class="docutils literal notranslate"><span class="pre">transposed=1</span></code>”</p></td>
</tr>
<tr class="row-even"><td><p>yolov8</p></td>
<td><p>0</p></td>
<td><p>NxTxD</p></td>
<td><p>Processing done in the model</p></td>
<td><p>Overall confidence missing</p></td>
</tr>
</tbody>
</table>
<p>Where:</p>
<blockquote>
<div><ul class="simple">
<li><p>N: number of samples, must be 1</p></li>
<li><p>C: number of classes detected</p></li>
<li><p>T: total number of detections</p></li>
<li><p>M: maximum number of detections</p></li>
<li><p>D: detection size (includes: bounding box deltas xywh, confidence, landmarks, per-class confidences)</p></li>
<li><p>A: number of anchors</p></li>
<li><p>H: heigth of the image in the pyramid</p></li>
<li><p>W: width of the image in the pyramid</p></li>
<li><p>P: number of images in the pyramid</p></li>
</ul>
</div></blockquote>
<p>Attributes for <code class="docutils literal notranslate"><span class="pre">retinanet_boxes</span></code> and <code class="docutils literal notranslate"><span class="pre">tflite_detection_input</span></code> formats:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 25%" />
<col style="width: 8%" />
<col style="width: 67%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Attribute</p></th>
<th class="head"><p>Default</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>class_index_base</p></td>
<td><p>0</p></td>
<td><p>Class index corresponding to the first element of the output vector</p></td>
</tr>
<tr class="row-odd"><td><p>transposed</p></td>
<td><p>0</p></td>
<td><p>Must be 1 if the output tensor uses the transposed format</p></td>
</tr>
<tr class="row-even"><td><p>anchors</p></td>
<td></td>
<td><p>Anchor points</p></td>
</tr>
<tr class="row-odd"><td><p>x_scale</p></td>
<td><p>10</p></td>
<td><p>See <code class="docutils literal notranslate"><span class="pre">x_scale</span></code> parameter in the <code class="docutils literal notranslate"><span class="pre">TFLite_Detection_PostProcess</span></code> layer</p></td>
</tr>
<tr class="row-even"><td><p>y_scale</p></td>
<td><p>10</p></td>
<td><p>See <code class="docutils literal notranslate"><span class="pre">y_scale</span></code> parameter in the <code class="docutils literal notranslate"><span class="pre">TFLite_Detection_PostProcess</span></code> layer</p></td>
</tr>
<tr class="row-odd"><td><p>h_scale</p></td>
<td><p>5</p></td>
<td><p>See <code class="docutils literal notranslate"><span class="pre">h_scale</span></code> parameter in the <code class="docutils literal notranslate"><span class="pre">TFLite_Detection_PostProcess</span></code> layer</p></td>
</tr>
<tr class="row-even"><td><p>w_scale</p></td>
<td><p>5</p></td>
<td><p>See <code class="docutils literal notranslate"><span class="pre">w_scale</span></code> parameter in the <code class="docutils literal notranslate"><span class="pre">TFLite_Detection_PostProcess</span></code> layer</p></td>
</tr>
</tbody>
</table>
<p>In this case, the anchor points can be defined using the build-in
variable <code class="docutils literal notranslate"><span class="pre">${ANCHORS}</span></code>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>anchors=${ANCHORS}
</pre></div>
</div>
<p>This variable is replaced at conversion time with the content of the <code class="docutils literal notranslate"><span class="pre">anchor</span></code> tensor
from the <code class="docutils literal notranslate"><span class="pre">TFLite_Detection_PostProcess</span></code> layer (if present in the model).</p>
<p>Attributes for <code class="docutils literal notranslate"><span class="pre">tflite_detection</span></code> format:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 25%" />
<col style="width: 8%" />
<col style="width: 67%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Attribute</p></th>
<th class="head"><p>Default</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>class_index_base</p></td>
<td><p>0</p></td>
<td><p>Class index corresponding to the first element of the output vector</p></td>
</tr>
<tr class="row-odd"><td><p>h_scale</p></td>
<td><p>0</p></td>
<td><p>Vertical scale of the detected boxes (normally the H of the input tensor)</p></td>
</tr>
<tr class="row-even"><td><p>w_scale</p></td>
<td><p>0</p></td>
<td><p>Horizontal scale of the detected boxes (normally the W of the input tensor)</p></td>
</tr>
</tbody>
</table>
<p>Attributes for <code class="docutils literal notranslate"><span class="pre">yolov5</span></code> and <code class="docutils literal notranslate"><span class="pre">yolov8</span></code> formats:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 25%" />
<col style="width: 8%" />
<col style="width: 67%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Attribute</p></th>
<th class="head"><p>Default</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>class_index_base</p></td>
<td><p>0</p></td>
<td><p>Class index corresponding to the first element of the output vector</p></td>
</tr>
<tr class="row-odd"><td><p>transposed</p></td>
<td><p>0</p></td>
<td><p>Must be 1 if the output tensor uses the transposed format</p></td>
</tr>
<tr class="row-even"><td><p>landmarks</p></td>
<td><p>0</p></td>
<td><p>Number of landmark points</p></td>
</tr>
<tr class="row-odd"><td><p>anchors</p></td>
<td></td>
<td><p>Anchor points. Not needed if processing done in the model</p></td>
</tr>
<tr class="row-even"><td rowspan="2"><p>h_scale</p></td>
<td rowspan="2"><p>0</p></td>
<td><p>Vertical scale of the detected boxes</p></td>
</tr>
<tr class="row-odd"><td><p>(normally the H of the input tensor when processing is done in the model)</p></td>
</tr>
<tr class="row-even"><td rowspan="2"><p>w_scale</p></td>
<td rowspan="2"><p>0</p></td>
<td><p>Horizontal scale of the detected boxes</p></td>
</tr>
<tr class="row-odd"><td><p>(normally the W of the input tensor when processing is done in the model)</p></td>
</tr>
<tr class="row-even"><td rowspan="3"><p>bb_normalized</p></td>
<td rowspan="3"><p>0</p></td>
<td><p>Must be 1 if the bounding box deltas are normalized (only for <cite>yolov8`</cite>)</p></td>
</tr>
<tr class="row-odd"><td><p>Indicates that bounding boxes are normalized to the range [0, 1]</p></td>
</tr>
<tr class="row-even"><td><p>while landmarks are in the range h_scale, wscale</p></td>
</tr>
</tbody>
</table>
<p>For <code class="docutils literal notranslate"><span class="pre">yolov5</span></code> format, the <code class="docutils literal notranslate"><span class="pre">anchors</span></code> attribute  must contain one entry for each pyramid element
from P0, where each entry is a list of the <code class="docutils literal notranslate"><span class="pre">x,y</span></code> anchor  deltas.
For example for yolov5s-face, the anchors are defined in
<a class="reference external" href="https://github.com/deepcam-cn/yolov5-face/blob/master/models/yolov5s.yaml">https://github.com/deepcam-cn/yolov5-face/blob/master/models/yolov5s.yaml</a> :</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- [4,5,  8,10,  13,16]  # P3/8
- [23,29,  43,55,  73,105]  # P4/16
- [146,217,  231,300,  335,433]  # P5/32
</pre></div>
</div>
<p>The corresponding outputs in the metafile can be defined as follows:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>outputs:
  - format: yolov5 landmarks=5 anchors=[[],[],[],[4,5,8,10,13,16],[23,29,43,55,73,105],[146,217,231,300,335,433]]
    dequantize: true
  - dequantize: true
  - dequantize: true
</pre></div>
</div>
</section>
</section>
<section id="building-sample-code">
<h2>Building Sample Code<a class="headerlink" href="#building-sample-code" title="Permalink to this headline"></a></h2>
<p>The source code of the sample applications (e.g. <code class="docutils literal notranslate"><span class="pre">synap_cli</span></code>, <code class="docutils literal notranslate"><span class="pre">synap_cli_ic</span></code>, etc) is included
in the SyNAP release, together with that of the SyNAP libraries. Users based on the <em>ASTRA</em> distribution
can build SyNAP using the provided Yocto recipe.</p>
<p>For other users building SyNAP code requires the following components installed:</p>
<ol class="arabic simple">
<li><p>VSSDK tree</p></li>
<li><p>cmake</p></li>
</ol>
<p>Build steps:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>cd synap/src
mkdir build
cd build
cmake -DVSSDK_DIR=/path/to/vssdk-directory -DCMAKE_INSTALL_PREFIX=install ..
make install
</pre></div>
</div>
<p>The above steps will create the binaries for the sample applications in
<code class="docutils literal notranslate"><span class="pre">synap/src/build/install/bin</span></code>. The binaries can then be pushed to the board
using <code class="docutils literal notranslate"><span class="pre">adb</span></code>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>cd synap/src/build/install/bin
adb push synap_cli_ic /vendor/bin
</pre></div>
</div>
<p>Users are free to change the source code provided to adapt it to their specific requirements.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="working_with_models.html" class="btn btn-neutral float-left" title="Working With Models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="npu_operators.html" class="btn btn-neutral float-right" title="Neural Network Processing Unit Operator Support" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, 2022, 2023, 2024, Synaptics.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>