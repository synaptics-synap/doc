<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Introduction &mdash; SyNAP 3.0.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Getting Started" href="getting_started.html" />
    <link rel="prev" title="SyNAP" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            SyNAP
          </a>
              <div class="version">
                3.0.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#online-model-conversion">Online Model Conversion</a></li>
<li class="toctree-l2"><a class="reference internal" href="#offline-model-conversion">Offline Model Conversion</a></li>
<li class="toctree-l2"><a class="reference internal" href="#npu-hardware-capabilities">NPU Hardware Capabilities</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="nnapi.html">Using Online Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">Reference Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="statistics.html">Statistics And Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="working_with_models.html">Working With Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="framework_api.html">Framework API</a></li>
<li class="toctree-l1"><a class="reference internal" href="npu_operators.html">Neural Network Processing Unit Operator Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="java.html">Direct Access In Android Applications</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">SyNAP</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Introduction</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline"></a></h1>
<p>The purpose of SyNAP is to support the execution of neural networks by taking advantage of the
available hardware accelerators.
The execution of a <em>Neural Network</em>, commonly called an <em>inference</em> or a <em>prediction</em>,  consists of
taking one or more inputs and applying a neural network to them to generate one or more outputs.
Each input and output is represented with an n-dimensional array of data, called a <em>Tensor</em>.
Execution takes place inside the Network Processing Unit (<em>NPU</em>) accelerator or in the <em>GPU</em> or directly
in the <em>CPU</em>.
In order to do this, the network has to be converted from its original representation (e.g.
Tensorflow Lite) to the internal SyNAP representation, optimized for the target hardware.</p>
<p>This conversion can occur at two different moments:</p>
<blockquote>
<div><ul class="simple">
<li><p>at runtime, when the network is going to be executed, by using a just-in-time compiler
and optimizer. We call this <em>Online Model Conversion</em>.</p></li>
<li><p>ahead of time, by applying offline conversion and optimization tools which generate a
precompiled representation of the network specific for the target hardware.
We call this <em>Offline Model Conversion</em>.</p></li>
</ul>
</div></blockquote>
<section id="online-model-conversion">
<h2>Online Model Conversion<a class="headerlink" href="#online-model-conversion" title="Permalink to this headline"></a></h2>
<p>Online model conversion allows to execute a model directly without any
intermediate steps. This is the most flexible method as all the required conversions and
optimizations are done on the fly at runtime, just before the model is executed. The price to be paid
for this is that model compilation takes some time (typically a few seconds) when the model
is first executed.
Another important limitation is that online execution is not available in a secure media path, that is
to process data in secure streams.</p>
<figure class="align-default" id="id1">
<img alt="_images/online_conversion.png" src="_images/online_conversion.png" />
<figcaption>
<p><span class="caption-number">Figure 1 </span><span class="caption-text">Online model conversion and execution</span><a class="headerlink" href="#id1" title="Permalink to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="offline-model-conversion">
<h2>Offline Model Conversion<a class="headerlink" href="#offline-model-conversion" title="Permalink to this headline"></a></h2>
<p>In this mode the network has to be converted from its original representation (e.g.
Tensorflow Lite) to the internal SyNAP representation, optimized for the target hardware.
Doing the optimization offline allows to perform the highest level of optimizations possible
without the tradeoffs of the just-in-time compiler.</p>
<p>In most cases the model conversion can be done with a one-line command using SyNAP toolkit.
SyNAP toolkit also supports more advanced operations, such as network quantization and preprocessing.
Optionally an offline model can also be signed and encrypted to support Synaptics SyKURE<sup>TM</sup>
secure inference technology.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>a compiled model is target-specific and will fail to execute on a different hardware</p>
</div>
<figure class="align-default" id="id2">
<img alt="_images/offline_conversion.png" src="_images/offline_conversion.png" />
<figcaption>
<p><span class="caption-number">Figure 2 </span><span class="caption-text">Offline model conversion and execution</span><a class="headerlink" href="#id2" title="Permalink to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="npu-hardware-capabilities">
<h2>NPU Hardware Capabilities<a class="headerlink" href="#npu-hardware-capabilities" title="Permalink to this headline"></a></h2>
<p>The NPU itsef actually consists of multiple units. These units can execute in parallel when possible
to reduce inference times as much as possible. Three types of units are available:</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>Convolutional Core</strong>: these units are highly optimized to execute convolutions.
Cannot be used to implement any other layer.</p></li>
<li><p><strong>Tensor Processor</strong>: optimized to execute highly parallel operations, such as tensor-add.
The <em>Lite</em> version is similar but supports a reduced operation set.</p></li>
<li><p><strong>Parellel Processing Unit</strong>: very flexible unit that can be programmed to process tensors
with customized kernels. It supports SIMD execution but it is less specialized (so less
efficient) than the Neural Network Engine and Parellel Processing Units.</p></li>
</ul>
</div></blockquote>
<p>In addition the NPU also contains an internal static RAM which is used to provide fast
access to the data and/or weights thus reducing the need to access the slower external memory
during processing.</p>
<figure class="align-default" id="id3">
<a class="reference internal image-reference" href="_images/NPU.png"><img alt="_images/NPU.png" src="_images/NPU.png" style="width: 752.4px; height: 435.59999999999997px;" /></a>
<figcaption>
<p><span class="caption-number">Figure 3 </span><span class="caption-text">NPU Architecture</span><a class="headerlink" href="#id3" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>The NPU of each SoC differ in the number of units it contains:</p>
<blockquote>
<div><table class="docutils align-default">
<colgroup>
<col style="width: 17%" />
<col style="width: 29%" />
<col style="width: 23%" />
<col style="width: 32%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>SoC</p></th>
<th class="head"><p>Neural Network Core</p></th>
<th class="head"><p>Tensor Processor</p></th>
<th class="head"><p>Parallel Processing Unit</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>VS640,
SL1640</p></td>
<td><p>4</p></td>
<td><p>2 + 4 Lite</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p>VS680,
SL1680</p></td>
<td><p>22</p></td>
<td><p>8</p></td>
<td><p>1</p></td>
</tr>
</tbody>
</table>
</div></blockquote>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="SyNAP" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="getting_started.html" class="btn btn-neutral float-right" title="Getting Started" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, 2022, 2023, 2024, Synaptics.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>